{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2103258_prac03.ipynb","provenance":[{"file_id":"1kX6E7TYXik-jG4b6G7DL_DIk3nbP3U1B","timestamp":1616034118537}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyN6O4k8GCDopxhn7RLcU6Z0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"i33z4PFj7SPF"},"source":["\\[SEP592\\] ì†Œí”„íŠ¸ì›¨ì–´ íŠ¹ê°• <ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤ ì…ë¬¸>\n","# 4ì£¼ì°¨ ì‹¤ìŠµ íŒŒíŠ¸\n","\n","> ê°•ì˜ì¼: 2021.03.25.\n","\n","ğŸ‘¤ ì‹¤ìŠµë‹´ë‹¹ì: ì„ì±„ê·  (KAIST ì „ì‚°í•™ë¶€) &nbsp;&nbsp; | &nbsp;&nbsp; ğŸ“§ Email: rayote@kaist.ac.kr\n","\n","---\n","<br />\n","\n","#### &nbsp;&nbsp; *ì‹¤ìŠµ ëª©í‘œ*\n","\n","*   ì‚¬ì „í•™ìŠµëœ VGG ëª¨ë¸ì„ Kerasì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ í™•ì¸í•¨.\n","*   Keras í™˜ê²½ì—ì„œ <u>RNN (Recurrent Neural Network)ì˜ êµ¬ì¡° ë° ì‚¬ìš©ë²•</u>ì„ í•™ìŠµí•¨.\n","\n","\n","\n","<br />\n","\n","#### &nbsp;&nbsp; *References*\n","\n","*   ê¹€íƒœì˜, â€œë¸”ë¡ê³¼ í•¨ê»˜ í•˜ëŠ” íŒŒì´ì¬ ë”¥ëŸ¬ë‹ ì¼€ë¼ìŠ¤,â€ ë””ì§€í„¸\n","ë¶ìŠ¤, 2017.\n","  * ê¹€íƒœì˜ì˜ ì¼€ë¼ìŠ¤ ë¸”ë¡œê·¸ <small>https://tykimos.github.io/lecture/</small>\n","\n","<br />\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"arW3XP-uLgkx"},"source":["##### *(ì°¸ê³ )* ê°ê°ì˜ ì½”ë“œ ì…€ì˜ ì‹¤í–‰ì‹œê°„ì„ ìë™ìœ¼ë¡œ ì¸¡ì •í•´ì£¼ëŠ” ëª¨ë“ˆì„ ì„¤ì¹˜í•¨."]},{"cell_type":"code","metadata":{"id":"QKkgeDyuLktL"},"source":["# ê° ì½”ë“œ ì…€ì˜ ì‹¤í–‰ì‹œê°„ ì¸¡ì • ëª¨ë“ˆ\n","!pip install ipython-autotime\n","\n","%load_ext autotime"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uzrYGRK2ixFg"},"source":["##### Keras ë²„ì „ ì°¨ì´ë¡œ ì‹¤ìŠµ ì‹œ ì—ëŸ¬ ë°œìƒí•˜ë¯€ë¡œ, êµ¬ë²„ì „ìœ¼ë¡œ ì¬ì„¤ì¹˜\n","\n","*   ì¬ì„¤ì¹˜ ë²„ì „ \n","    - keras 2.3.1\n","    -   tensorflow 2.2.0 "]},{"cell_type":"code","metadata":{"id":"DAzsOyiziwxB"},"source":["# ê¸°ì¡´ keras ì‚­ì œí•˜ê¸°\n","!pip uninstall -y keras\n","!pip uninstall -y tensorflow\n","\n","# êµ¬ë²„ì „ ì¬ì„¤ì¹˜\n","!pip install keras==2.3.1\n","!pip install tensorflow==2.2.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NZByadnfjafF"},"source":["import keras\n","print(keras.__version__)\n","\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eVRPshpP4Nhq"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sH--H1yJOPXv"},"source":["## **<small>(ì§€ë‚œ ì‹¤ìŠµ cont'd)</small> 5. ì‚¬ì „í•™ìŠµëœ VGG ëª¨ë¸ ì‚¬ìš©**"]},{"cell_type":"markdown","metadata":{"id":"SmM7bAS6O6tX"},"source":["### **ë„ì „ ì‹œí—˜ì…‹ ë°ì´í„° ì¤€ë¹„**"]},{"cell_type":"code","metadata":{"id":"zGxfL1OiO5ax"},"source":["# Colab í™˜ê²½ì— ë°ì´í„° ë°›ê¸°\n","!wget https://github.com/tykimos/tykimos.github.io/raw/master/warehouse/2017-3-8-CNN_Data_Augmentation_hard_handwriting_shape.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TMp-43YnO5a0"},"source":["# ë°ì´í„° ê²½ë¡œ(warehouse/)ì— ì••ì¶• í•´ì œí•˜ê¸°\n","!unzip 2017-3-8-CNN_Data_Augmentation_hard_handwriting_shape.zip -d warehouse"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"smyStQBQRpaw"},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","# ëœë¤ì‹œë“œ ê³ ì •ì‹œí‚¤ê¸°\n","np.random.seed(3)\n","\n","# ë°ì´í„° ìƒì„±í•˜ê¸°\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","        'warehouse/hard_handwriting_shape/train',\n","        target_size=(224, 224),   # VGGëŠ” ì´ë¯¸ì§€ë¥¼ 224Ã—224 í¬ê¸° ì‚¬ìš©\n","        batch_size=3,\n","        class_mode='categorical')\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","test_generator = test_datagen.flow_from_directory(\n","        'warehouse/hard_handwriting_shape/test',\n","        target_size=(224, 224),   # VGGëŠ” ì´ë¯¸ì§€ë¥¼ 224Ã—224 í¬ê¸° ì‚¬ìš©\n","        batch_size=3,\n","        class_mode='categorical')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ToB1sCtdOPXw"},"source":["### **VGG-16 ëª¨ë¸**\n","\n","*ì°¸ì¡° ë ˆí¼ëŸ°ìŠ¤*\n","\n","https://machinelearningmastery.com/use-pre-trained-vgg-model-classify-objects-photographs/\n","\n","<br />\n","\n","**ì£¼ìš” íŒŒë¼ë¯¸í„°**\n","\n","*   `include_top (True)`: \n","  - Whether or not to include the output layers for the model. You donâ€™t need these if you are fitting the model on your own problem.\n","*   `weights ('imagenet')`: \n","  - What weights to load. You can specify None to not load pre-trained weights if you are interested in training the model yourself from scratch.\n","*   `input_tensor (None)`: \n","  - A new input layer if you intend to fit the model on new data of a different size.\n","*   `input_shape (None)`: \n","  - The size of images that the model is expected to take if you change the input layer.\n","*   `pooling (None)`: \n","  - The type of pooling to use when you are training a new set of output layers.\n","*   `classes (1000)`: \n","  - The number of classes (e.g. size of output vector) for the model."]},{"cell_type":"code","metadata":{"id":"GLW6XGNvOPXy"},"source":["from keras.applications.vgg16 import VGG16\n","model = VGG16()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Lrc6RAgOPXz"},"source":["from IPython.display import SVG\n","from keras.utils.vis_utils import model_to_dot\n","\n","%matplotlib inline\n","\n","SVG(model_to_dot(model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c-fH0exVOPXz"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5l7pvxzDOPX0"},"source":["##### *ì…ë ¥ ì´ë¯¸ì§€ ë°ì´í„° ì¤€ë¹„*"]},{"cell_type":"markdown","metadata":{"id":"2n-43mHPOPX0"},"source":["VGG ëª¨ë¸ì—ì„œëŠ” ì…ë ¥ ì´ë¯¸ì§€ë¥¼ 224Ã—224 í¬ê¸°ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"id":"8yl9yoJdOPX1"},"source":["from keras.preprocessing.image import load_img\n","# load an image from file\n","path_img = 'warehouse/hard_handwriting_shape/train/triangle/triangle001.png'\n","image = load_img(path_img, target_size=(224, 224))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PGTuU0JXOPX2"},"source":["`Numpy` ë°°ì—´ë¡œ ë³€ê²½í•˜ê³ , ê¸°ì¡´ VGG ëª¨ë¸ì— ë§ë„ë¡ ì¶”ê°€ dimensionì„ í¬í•¨í•˜ë„ë¡ `reshape()` í•©ë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"id":"TPXUdbHqOPX2"},"source":["from keras.preprocessing.image import img_to_array\n","# convert the image pixels to a numpy array\n","image = img_to_array(image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kV1RurawOPX2"},"source":["# reshape data for the model\n","image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FZtpMc4MOPX2"},"source":["Kerasì—ì„œ ì œê³µí•˜ëŠ” VGGëª¨ë¸ì˜ ì…ë ¥ ì „ì²˜ë¦¬ í•¨ìˆ˜ `preprocess_input()`ì„ ì ìš©í•©ë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"id":"IWDo05EaOPX3"},"source":["from keras.applications.vgg16 import preprocess_input\n","# prepare the image for the VGG model\n","image = preprocess_input(image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CWr0alTAOPX3"},"source":["##### *ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ì‹¤í–‰*"]},{"cell_type":"code","metadata":{"id":"44-P-Ug-OPX3"},"source":["# predict the probability across all output classes\n","yhat = model.predict(image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WZYEOT6FOPX3"},"source":["##### *ì˜ˆì¸¡ê²°ê³¼ í•´ì„*"]},{"cell_type":"code","metadata":{"id":"Ozwa-GZ9OPX3"},"source":["from keras.applications.vgg16 import decode_predictions\n","# convert the probabilities to class labels\n","label = decode_predictions(yhat)\n","# retrieve the most likely result, e.g. highest probability\n","label = label[0][0]\n","# print the classification\n","print('%s (%.2f%%)' % (label[1], label[2]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4_oekJQOPX3"},"source":["import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","plt.imshow(image.reshape(224, 224, 3))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RUxIfJxpOPX4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tYSK9RBxOPX4"},"source":["#### *ì „ì²´ ì½”ë“œ ì¬ì •ë¦¬ (í•¨ìˆ˜í™”)*"]},{"cell_type":"code","metadata":{"id":"VRZbiUsIOPX4"},"source":["from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.vgg16 import preprocess_input\n","\n","# ì…ë ¥ ì „ì²˜ë¦¬ í•¨ìˆ˜\n","def preproc_image_vgg(path_img):\n","  # load an image from file\n","  image = load_img(path_img, target_size=(224, 224))\n","\n","  # convert the image pixels to a numpy array\n","  image = img_to_array(image)\n","\n","  # reshape data for the model\n","  image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","\n","  # prepare the image for the VGG model\n","  image = preprocess_input(image)\n","\n","  return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NemXwwi7OPX4"},"source":["from keras.applications.vgg16 import decode_predictions\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# ê²°ê³¼ í•´ì„ ë° ì¶œë ¥ í•¨ìˆ˜\n","def print_result_vgg(yhat, image):\n","  # convert the probabilities to class labels\n","  label = decode_predictions(yhat)\n","  # retrieve the most likely result, e.g. highest probability\n","  label = label[0][0]\n","  # print the classification\n","  print('> Predicted Label=  %s (%.2f%%)' % (label[1], label[2]*100))\n","\n","  # show an image\n","  plt.imshow(image.reshape(224, 224, 3))\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wd5lJfJ9OPX4"},"source":["# VGGë¥¼ í™œìš©í•œ ì „ì²´ ì˜ˆì¸¡ê³¼ì • í•¨ìˆ˜\n","def predict_vgg(path_img):\n","  image = preproc_image_vgg(path_img)\n","\n","  # predict the probability across all output classes\n","  yhat = model.predict(image)\n","\n","  print_result_vgg(yhat, image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"awOmgxpJOPX5"},"source":["##### *ì‹¤í–‰ê²°ê³¼ í…ŒìŠ¤íŠ¸*"]},{"cell_type":"code","metadata":{"id":"dz_EtDm5OPX5"},"source":["predict_vgg('warehouse/hard_handwriting_shape/train/triangle/triangle001.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c4vpMOKMOPX5"},"source":["predict_vgg('warehouse/hard_handwriting_shape/train/circle/circle001.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2U_CH2DROPX5"},"source":["predict_vgg('warehouse/hard_handwriting_shape/train/rectangle/rectangle001.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZnBN2PnHOoVG"},"source":["### **VGG-16 ëª¨ë¸ì— ëŒ€í•œ Fine-tuning**"]},{"cell_type":"markdown","metadata":{"id":"0EESrCEmPNB0"},"source":["#### *ëª¨ë¸ ì¶”ê°€ êµ¬ì„±í•˜ê¸° (1) - ì˜ˆì¸¡ ë ˆì´ì–´ ì¶”ê°€*"]},{"cell_type":"code","metadata":{"id":"6QSlqL77OPX5"},"source":["from keras.layers import Dense, GlobalAveragePooling1D\n","from keras import Model\n","\n","base_model = VGG16()\n","\n","# let's add a fully-connected layer\n","x = base_model.output\n","x = Dense(256, activation='relu')(x)\n","\n","# and a logistic layer -- let's say we have 3 classes\n","predictions = Dense(3, activation='softmax')(x)\n","\n","# this is the model we will train\n","model = Model(inputs=base_model.input, outputs=predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_-5DK7B04NfK"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"op4QSVsl4Nca"},"source":["# first: train only the top layers (which were randomly initialized)\n","# i.e. freeze all convolutional layers\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# compile the model (should be done *after* setting layers to non-trainable)\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q31CqSVbOOPZ"},"source":["# ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸°\n","model.fit_generator(\n","        train_generator,\n","        steps_per_epoch=15,\n","        epochs=10,\n","        validation_data=test_generator,\n","        validation_steps=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HtW6eIG2Z7oV"},"source":["# ëª¨ë¸ í‰ê°€í•˜ê¸°\n","print(\"-- Evaluate --\")\n","scores = model2.evaluate_generator(test_generator, steps=15)\n","print(\"%s: %.2f%%\" %(model2.metrics_names[1], scores[1]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YAyNolVjWt0A"},"source":["#### *ëª¨ë¸ ì¶”ê°€ êµ¬ì„±í•˜ê¸° (2) - ì‚¬ì „ëª¨ë¸ ì¼ë¶€ ë ˆì´ì–´ í™œìš©*"]},{"cell_type":"code","metadata":{"id":"uCUK1NI3OOKQ"},"source":["base_model2 = VGG16()\n","\n","# let's add a fully-connected layer\n","x = base_model2.output\n","x = Dense(64, activation='relu')(x)\n","\n","# and a logistic layer -- let's say we have 3 classes\n","predictions = Dense(3, activation='softmax')(x)\n","\n","# this is the model we will train\n","model2 = Model(inputs=base_model2.input, outputs=predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o4_4437oXNur"},"source":["# we chose to train the top 2 inception blocks, i.e. we will freeze\n","# other layers\n","for layer in base_model2.layers[:-2]:\n","    layer.trainable = False\n","for layer in base_model2.layers[-2:]:\n","    layer.trainable = True\n","\n","# compile the model (should be done *after* setting layers to non-trainable)\n","model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ivUAAY6rXlj8"},"source":["# ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸°\n","model2.fit_generator(\n","        train_generator,\n","        steps_per_epoch=15,\n","        epochs=10,\n","        validation_data=test_generator,\n","        validation_steps=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QblwyY1ZZ47A"},"source":["# ëª¨ë¸ í‰ê°€í•˜ê¸°\n","print(\"-- Evaluate --\")\n","scores = model2.evaluate_generator(test_generator, steps=15)\n","print(\"%s: %.2f%%\" %(model2.metrics_names[1], scores[1]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g9Duge9tYEJv"},"source":["---\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"TPzu-4Td5jJu"},"source":["## **1. LSTM ëª¨ë¸ì˜ ê¸°ë³¸ ê°œë…**\n"]},{"cell_type":"markdown","metadata":{"id":"4UX7AJp45L-7"},"source":["ìˆœí™˜ ì‹ ê²½ë§ ëª¨ë¸ì€ ìˆœì°¨ì ì¸ ìë£Œì—ì„œ ê·œì¹™ì ì¸ íŒ¨í„´ì„ ì¸ì‹í•˜ê±°ë‚˜ ê·¸ ì˜ë¯¸ë¥¼ ì¶”ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìˆœì°¨ì ì´ë¼ëŠ” íŠ¹ì„± ë•Œë¬¸ì— ê°„ë‹¨í•œ ë ˆì´ì–´ë¡œë„ ë‹¤ì–‘í•œ í˜•íƒœì˜ ëª¨ë¸ì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¼€ë¼ìŠ¤ì—ì„œ ì œê³µí•˜ëŠ” ìˆœí™˜ ì‹ ê²½ë§ ë ˆì´ì–´ëŠ” SimpleRNN, GRU, LSTMì´ ìˆìœ¼ë‚˜ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” LSTMì— ëŒ€í•´ì„œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. "]},{"cell_type":"markdown","metadata":{"id":"90kjNrIr5L-8"},"source":["---\n","\n","### **ê¸´ ì‹œí€€ìŠ¤ë¥¼ ê¸°ì–µí•  ìˆ˜ ìˆëŠ” LSTM (Long Short-Term Memory units)  ë ˆì´ì–´**\n","\n","LSTM ë ˆì´ì–´ëŠ” ì•„ë˜ì™€ ê°™ì´ ê°„ë‹¨íˆ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Fkk14wvl5zKM"},"source":["#### *ì…ë ¥ í˜•íƒœ*\n","\n","    LSTM(3, input_dim=1)\n","\n","ê¸°ë³¸ ì¸ìëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n","* ì²«ë²ˆì§¸ ì¸ì : ë©”ëª¨ë¦¬ ì…€ì˜ ê°œìˆ˜ì…ë‹ˆë‹¤.\n","* input_dim : ì…ë ¥ ì†ì„± ìˆ˜ ì…ë‹ˆë‹¤.\n","\n","ì´ëŠ” ì•ì„œ ì‚´í´ë³¸ Dense ë ˆì´ì–´ í˜•íƒœì™€ ë¹„ìŠ·í•©ë‹ˆë‹¤. ì²«ë²ˆì§¸ ì¸ìì¸ ë©”ëª¨ë¦¬ ì…€ì˜ ê°œìˆ˜ëŠ” ê¸°ì–µìš©ëŸ‰ ì •ë„ì™€ ì¶œë ¥ í˜•íƒœë¥¼ ê²°ì •ì§“ìŠµë‹ˆë‹¤. Dense ë ˆì´ì–´ì—ì„œì˜ ì¶œë ¥ ë‰´ëŸ° ìˆ˜ì™€ ë¹„ìŠ·í•˜ë‹¤ê³  ë³´ì‹œë©´ ë©ë‹ˆë‹¤. input_dimì—ëŠ” Dense ë ˆì´ì–´ì™€ ê°™ì´ ì¼ë°˜ì ìœ¼ë¡œ ì†ì„±ì˜ ê°œìˆ˜ê°€ ë“¤ì–´ê°‘ë‹ˆë‹¤. \n","\n","    Dense(3, input_dim=1)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Y7ctneAB52hd"},"source":["LSTMì˜ í•œ ê°€ì§€ ì¸ìì— ëŒ€í•´ ë” ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\n","\n","    LSTM(3, input_dim=1, input_length=4)\n","\n","* input_length : ì‹œí€€ìŠ¤ ë°ì´í„°ì˜ ì…ë ¥ ê¸¸ì´\n","\n","Denseì™€ LSTMì„ ë¸”ë¡ìœ¼ë¡œ ë„ì‹í™” í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì™¼ìª½ì´ Denseì´ê³ , ì¤‘ì•™ì´ input_lengthê°€ 1ì¸ LSTMì´ê³  ì˜¤ë¥¸ìª½ì´ input_lengthê°€ 4ì¸ LSTM ì…ë‹ˆë‹¤. ì‚¬ì‹¤ LSTMì˜ ë‚´ë¶€êµ¬ì¡°ëŠ” ë³µì¡í•˜ì§€ë§Œ ê°„ì†Œí™”í•˜ì—¬ ì™¸í˜•ë§Œ í‘œì‹œí•œ ê²ƒì…ë‹ˆë‹¤. Dense ë ˆì´ì–´ì™€ ë¹„êµí•œë‹¤ë©´ íˆë“  ë‰´ëŸ°ë“¤ì´ ë°–ìœ¼ë¡œ ë„ì¶œë˜ì–´ ìˆìŒì„ ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ì˜¤ë¥¸ìª½ ë¸”ë¡ì¸ ê²½ìš° input_lengthê°€ ê¸¸ë‹¤ê³  í•´ì„œ ê° ì…ë ¥ë§ˆë‹¤ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì¤‘ì•™ì— ìˆëŠ” ë¸”ë¡ì„ ì…ë ¥ ê¸¸ì´ ë§Œí¼ ì—°ê²°í•œ ê²ƒì´ê¸° ë•Œë¬¸ì— ëª¨ë‘ ë™ì¼í•œ ê°€ì¤‘ì¹˜ë¥¼ ê³µìœ í•©ë‹ˆë‹¤.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_LSTM1.png)"]},{"cell_type":"markdown","metadata":{"id":"99sP_IRG5L-9"},"source":["#### *ì¶œë ¥ í˜•íƒœ*\n","\n","* return_sequences : ì‹œí€€ìŠ¤ ì¶œë ¥ ì—¬ë¶€\n","\n","LSTM ë ˆì´ì–´ëŠ” return_sequences ì¸ìì— ë”°ë¼ ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ì—ì„œ í•œ ë²ˆë§Œ ì¶œë ¥í•  ìˆ˜ ìˆê³  ê° ì‹œí€€ìŠ¤ì—ì„œ ì¶œë ¥ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. many to many ë¬¸ì œë¥¼ í’€ê±°ë‚˜ LSTM ë ˆì´ì–´ë¥¼ ì—¬ëŸ¬ê°œë¡œ ìŒ“ì•„ì˜¬ë¦´ ë•ŒëŠ” return_sequence=True ì˜µì…˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ìì„¸í•œ ê²ƒì€ ë’¤ì—ì„œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. ì•„ë˜ ê·¸ë¦¼ì—ì„œ ì™¼ìª½ì€ return_sequences=Falseì¼ ë•Œ, ì˜¤ë¥¸ìª½ì€ return_sequence=Trueì¼ ë•Œì˜ í˜•ìƒì…ë‹ˆë‹¤.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_LSTM2.png)"]},{"cell_type":"markdown","metadata":{"id":"yXV6iIAk5L-9"},"source":["#### *ìƒíƒœìœ ì§€(stateful) ëª¨ë“œ*\n","\n","* stateful : ìƒíƒœ ìœ ì§€ ì—¬ë¶€\n","\n","í•™ìŠµ ìƒ˜í”Œì˜ ê°€ì¥ ë§ˆì§€ë§‰ ìƒíƒœê°€ ë‹¤ìŒ ìƒ˜í”Œ í•™ìŠµ ì‹œì— ì…ë ¥ìœ¼ë¡œ ì „ë‹¬ ì—¬ë¶€ë¥¼ ì§€ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. í•˜ë‚˜ì˜ ìƒ˜í”Œì€ 4ê°œì˜ ì‹œí€€ìŠ¤ ì…ë ¥ì´ ìˆê³ , ì´ 3ê°œì˜ ìƒ˜í”Œì´ ìˆì„ ë•Œ, ì•„ë˜ ê·¸ë¦¼ì—ì„œ ìœ„ì˜ ë¸”ë¡ë“¤ì€ stateful=Falseì¼ ë•Œì˜ í˜•ìƒì´ê³ , ì•„ë˜ ë¸”ë¡ë“¤ì€ stateful=Trueì¼ ë•Œì˜ í˜•ìƒì…ë‹ˆë‹¤. ë„ì¶œëœ í˜„ì¬ ìƒíƒœì˜ ê°€ì¤‘ì¹˜ê°€ ë‹¤ìŒ ìƒ˜í”Œ í•™ìŠµ ì‹œì˜ ì´ˆê¸° ìƒíƒœë¡œ ì…ë ¥ë¨ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤."]},{"cell_type":"markdown","metadata":{"id":"58slSSad5L--"},"source":["![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_LSTM3.png)"]},{"cell_type":"markdown","metadata":{"id":"8fEo9Fzj5L--"},"source":["---\n","\n","### ìš”ì•½\n","\n","ìˆœí™˜ ì‹ ê²½ë§ ë ˆì´ì–´ ì¤‘ LSTM ë ˆì´ì–´ì— ëŒ€í•´ì„œ ì•Œì•„ë´¤ìŠµë‹ˆë‹¤. ì‚¬ìš©ë²•ì€ Dense ë ˆì´ì–´ì™€ ë¹„ìŠ·í•˜ì§€ë§Œ ì‹œí€€ìŠ¤ ì¶œë ¥ ì—¬ë¶€ì™€ ìƒíƒœìœ ì§€ ëª¨ë“œ ì„¤ì •ìœ¼ë¡œ ë‹¤ì–‘í•œ í˜•íƒœì˜ ì‹ ê²½ë§ì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."]},{"cell_type":"markdown","metadata":{"id":"u1-lXkpD6hR-"},"source":["## **2. LSTM ëª¨ë¸ ì‹œì‘í•˜ê¸°**\n"]},{"cell_type":"markdown","metadata":{"id":"CGrPESdk6DpL"},"source":["ë³¸ ê°•ì¢Œì—ì„œëŠ” ê°„ë‹¨í•œ ìˆœí™˜ ì‹ ê²½ë§ ëª¨ë¸ì„ ë§Œë“¤ì–´ë´…ë‹ˆë‹¤. ëŠ˜ ê·¸ë ‡ë“¯ì´ ë‹¤ìŒê³¼ ê°™ì€ ìˆœì„œë¡œ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.\n","\n","1. ë¬¸ì œ ì •ì˜í•˜ê¸°\n","1. ë°ì´í„°ì…‹ ì¤€ë¹„í•˜ê¸°\n","1. ëª¨ë¸ êµ¬ì„±í•˜ê¸°\n","1. ëª¨ë¸ ì—®ê¸°\n","1. ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸°\n","1. ëª¨ë¸ ì‚¬ìš©í•˜ê¸°"]},{"cell_type":"markdown","metadata":{"id":"f7SMvf8A7jQ8"},"source":["### *ëª¨ë“ˆ ì„í¬íŠ¸*"]},{"cell_type":"code","metadata":{"id":"TRsLnl_W6DpL"},"source":["import matplotlib.pyplot"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cagrMse06DpM"},"source":["import numpy as np\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Dropout\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import matplotlib.pyplot as plt\n","\n","import theano\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sG9uEdX76DpN"},"source":["### *ë°ì´í„° ìƒì„±*"]},{"cell_type":"code","metadata":{"id":"6Qde4RIx6DpN"},"source":["dataset = np.cos(np.arange(1000)*(20*np.pi/1000))[:,None]\n","\n","plt.plot(dataset)\n","\n","dataset.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"gbnOHLnl6DpN"},"source":["# convert an array of values into a dataset matrix\n","def create_dataset(dataset, look_back=1):\n","    dataX, dataY = [], []\n","    for i in range(len(dataset)-look_back):\n","        dataX.append(dataset[i:(i+look_back), 0])\n","        dataY.append(dataset[i + look_back, 0])\n","    return np.array(dataX), np.array(dataY)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OEfy83UZ6DpO"},"source":["### *í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ (Window of 20 time steps)*"]},{"cell_type":"markdown","metadata":{"id":"1BeNCecKJCjh"},"source":["`look_back`ì— ì§€ì •ëœ `20`ê°œ ë§Œí¼ì˜ ì´ì „ ê°’ì„ ë³´ê³ , ê·¸ ë‹¤ìŒ `1`ê°œë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•¨."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"vK752u966DpO"},"source":["look_back = 20\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","dataset = scaler.fit_transform(dataset)\n","\n","# split into train and test sets\n","train_size = int(len(dataset) * 0.67)\n","test_size = len(dataset) - train_size\n","train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n","\n","trainX, trainY = create_dataset(train, look_back)\n","testX, testY = create_dataset(test, look_back)\n","\n","trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n","testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qf9JSC6pJW6L"},"source":["`train`ì— í¬í•¨ëœ ë°ì´í„° ì „ì²´ ê°œìˆ˜ëŠ” `670`ê°œ"]},{"cell_type":"code","metadata":{"id":"Qi9x-URU6DpO"},"source":["print(train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O8D4zW2MJddu"},"source":["ê·¸ ì¤‘ì—ì„œ, í•™ìŠµë°ì´í„° `trainX`ëŠ” ê¸¸ì´ `20`ê°œ ë‹¨ìœ„ë¡œ êµ¬ì„±ë˜ì–´, ì´ `650`ê°œ"]},{"cell_type":"code","metadata":{"id":"cq05DSyd6DpP"},"source":["print(trainX.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bv_LADs2J0FZ"},"source":["`trainY`ì˜ ê²½ìš°ì—ë„ ìŒì„ ì´ë£¨ì–´ êµ¬ì„±ë˜ë¯€ë¡œ, ì´ `650`ê°œ"]},{"cell_type":"code","metadata":{"id":"1wIc12356DpP"},"source":["print(trainY.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sG65IJQ6J_pc"},"source":["### *ê°„ë‹¨í•œ LSTM ëª¨ë¸ í•™ìŠµ*\n"]},{"cell_type":"code","metadata":{"id":"hTz4_avr6DpQ"},"source":["# create and fit the LSTM network\n","batch_size = 1\n","model = Sequential()\n","model.add(LSTM(32,input_dim=1))\n","model.add(Dropout(0.3))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adam')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"V9-mGxWc6DpQ"},"source":["model.fit(trainX, trainY, nb_epoch=10, batch_size=batch_size, verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4byOxpPQ6DpQ"},"source":["trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n","print('Train Score: ', trainScore)\n","testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n","print('Test Score: ', testScore)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IeT7NQk06DpQ"},"source":["print(trainX[-1][1:].shape)\n","print()\n","print(trainX[-1][1:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"8mXWcU_J6DpR"},"source":["look_ahead = 250\n","trainPredict = [np.vstack([trainX[-1][1:], trainY[-1]])]\n","predictions = np.zeros((look_ahead,1))\n","for i in range(look_ahead):\n","    predict = model.predict(np.array([trainPredict[-1]]), batch_size=batch_size)\n","    predictions[i] = predict\n","    trainPredict.append(np.vstack([trainPredict[-1][1:], predict]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B4HF1Scn6DpR"},"source":["plt.figure(figsize=(12,5))\n","# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n","plt.plot(np.arange(look_ahead), predictions,'r-.', label=\"prediction\")\n","plt.plot(np.arange(look_ahead), dataset[train_size:(train_size+look_ahead)], label=\"test function\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EgpGImtp6DpR"},"source":["### *Stateful LSTMs*"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"KFTqQCJ36DpR"},"source":["look_back = 20\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","dataset = scaler.fit_transform(dataset)\n","\n","# split into train and test sets\n","train_size = int(len(dataset) * 0.67)\n","test_size = len(dataset) - train_size\n","train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n","\n","trainX, trainY = create_dataset(train, look_back)\n","testX, testY = create_dataset(test, look_back)\n","\n","trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n","testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pT5PbAm_6DpR"},"source":["# create and fit the LSTM network\n","batch_size = 1\n","model = Sequential()\n","# model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n","# model.add(Dropout(0.3))\n","# model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n","# model.add(Dropout(0.3))\n","model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n","model.add(Dropout(0.3))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","for i in range(10):\n","    print('epochs : %d ' % (i+1) )\n","    model.fit(trainX, trainY, nb_epoch=1, batch_size=batch_size, verbose=2, shuffle=False)\n","    model.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XMJSIF9a6DpS"},"source":["trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n","print('Train Score: ', trainScore)\n","testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n","print('Test Score: ', testScore)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"lefedAnO6DpS"},"source":["look_ahead = 250\n","trainPredict = [np.vstack([trainX[-1][1:], trainY[-1]])]\n","predictions = np.zeros((look_ahead,1))\n","for i in range(look_ahead):\n","    prediction = model.predict(np.array([trainPredict[-1]]), batch_size=batch_size)\n","    predictions[i] = prediction\n","    trainPredict.append(np.vstack([trainPredict[-1][1:],prediction]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RcCdQEGC6DpS"},"source":["plt.figure(figsize=(12,5))\n","# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n","plt.plot(np.arange(look_ahead),predictions,'r-.',label=\"prediction\")\n","plt.plot(np.arange(look_ahead),dataset[train_size:(train_size+look_ahead)],label=\"test function\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"72Xre8jvNou_"},"source":["### *ê·¸ ì™¸ ì°¸ê³ ìš© ì†ŒìŠ¤ì½”ë“œ*"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"fMtPBW426DpS"},"source":["#### Stateful LSTMs with wider window"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"doc9k3cL6DpS"},"source":["look_back = 40\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","dataset = scaler.fit_transform(dataset)\n","\n","# split into train and test sets\n","train_size = int(len(dataset) * 0.67)\n","test_size = len(dataset) - train_size\n","train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n","\n","trainX, trainY = create_dataset(train, look_back)\n","testX, testY = create_dataset(test, look_back)\n","\n","trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n","testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2aiJimfo6DpS"},"source":["%%time\n","theano.config.compute_test_value = \"ignore\"\n","# create and fit the LSTM network\n","batch_size = 1\n","model = Sequential()\n","# model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n","# model.add(Dropout(0.3))\n","# model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n","# model.add(Dropout(0.3))\n","model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n","model.add(Dropout(0.3))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","for i in range(200):\n","    model.fit(trainX, trainY, nb_epoch=1, batch_size=batch_size, verbose=0, shuffle=False)\n","    model.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYULgw3V6DpT"},"source":["trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n","print('Train Score: ', trainScore)\n","testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n","print('Test Score: ', testScore)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"1pG-OC516DpU"},"source":["look_ahead = 250\n","trainPredict = [np.vstack([trainX[-1][1:], trainY[-1]])]\n","predictions = np.zeros((look_ahead,1))\n","for i in range(look_ahead):\n","    prediction = model.predict(np.array([trainPredict[-1]]), batch_size=batch_size)\n","    predictions[i] = prediction\n","    trainPredict.append(np.vstack([trainPredict[-1][1:],prediction]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZcmAjRhG6DpU"},"source":["plt.figure(figsize=(12,5))\n","# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n","plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n","plt.plot(np.arange(look_ahead),dataset[train_size:(train_size+look_ahead)],label=\"test function\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4EA1oxOs6DpU"},"source":["#### Stateful LSTMs, Stacked"]},{"cell_type":"code","metadata":{"id":"7qY3UhiB6DpU"},"source":["%%time\n","theano.config.compute_test_value = \"ignore\"\n","# create and fit the LSTM network\n","batch_size = 1\n","model = Sequential()\n","model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n","model.add(Dropout(0.3))\n","model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n","model.add(Dropout(0.3))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","for i in range(200):\n","    model.fit(trainX, trainY, nb_epoch=1, batch_size=batch_size, verbose=0, shuffle=False)\n","    model.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xJquKM826DpV"},"source":["trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n","print('Train Score: ', trainScore)\n","testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n","print('Test Score: ', testScore)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"hAbUcJ5P6DpV"},"source":["look_ahead = 250\n","trainPredict = [np.vstack([trainX[-1][1:], trainY[-1]])]\n","predictions = np.zeros((look_ahead,1))\n","for i in range(look_ahead):\n","    prediction = model.predict(np.array([trainPredict[-1]]), batch_size=batch_size)\n","    predictions[i] = prediction\n","    trainPredict.append(np.vstack([trainPredict[-1][1:],prediction]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hXBjrL326DpV"},"source":["plt.figure(figsize=(12,5))\n","# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n","plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n","plt.plot(np.arange(look_ahead),dataset[train_size:(train_size+look_ahead)],label=\"test function\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K4HsEN3g6DpW"},"source":["#### Stateful LSTM stacked DEEPER!"]},{"cell_type":"code","metadata":{"id":"mxim6tKg6DpW"},"source":["%%time\n","theano.config.compute_test_value = \"ignore\"\n","# create and fit the LSTM network\n","batch_size = 1\n","model = Sequential()\n","for i in range(2):\n","    model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n","    model.add(Dropout(0.3))\n","model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n","model.add(Dropout(0.3))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","for i in range(200):\n","    model.fit(trainX, trainY, nb_epoch=1, batch_size=batch_size, verbose=0, shuffle=False)\n","    model.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r35EMtaj6DpW"},"source":["trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n","print('Train Score: ', trainScore)\n","testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n","print('Test Score: ', testScore)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"ou-M4np26DpW"},"source":["look_ahead = 250\n","trainPredict = [np.vstack([trainX[-1][1:], trainY[-1]])]\n","predictions = np.zeros((look_ahead,1))\n","for i in range(look_ahead):\n","    prediction = model.predict(np.array([trainPredict[-1]]), batch_size=batch_size)\n","    predictions[i] = prediction\n","    trainPredict.append(np.vstack([trainPredict[-1][1:],prediction]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1xelE066DpW"},"source":["plt.figure(figsize=(12,5))\n","# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n","plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n","plt.plot(np.arange(look_ahead),dataset[train_size:(train_size+look_ahead)],label=\"test function\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rcpCUnhm6DpX"},"source":["#### Normal Deep Learning in Keras"]},{"cell_type":"code","metadata":{"id":"YjbZZHxX6DpX"},"source":["%%time\n","trainX = np.squeeze(trainX)\n","testX = np.squeeze(testX)\n","theano.config.compute_test_value = \"ignore\"\n","# create and fit the LSTM network\n","batch_size = 1\n","model = Sequential()\n","model.add(Dense(output_dim=32,input_dim=40,activation=\"relu\"))\n","model.add(Dropout(0.3))\n","for i in range(2):\n","    model.add(Dense(output_dim=32,activation=\"relu\"))\n","    model.add(Dropout(0.3))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adagrad')\n","model.fit(trainX, trainY, nb_epoch=100, batch_size=32, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P4FSA5s66DpX"},"source":["trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n","print('Train Score: ', trainScore)\n","testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n","print('Test Score: ', testScore)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EF1rUMg06DpX"},"source":["look_ahead = 250\n","xval = np.hstack([trainX[-1][1:], trainY[-1]])[None,:]\n","predictions = np.zeros((look_ahead,1))\n","for i in range(look_ahead):\n","    prediction = model.predict(xval, batch_size=32)\n","    predictions[i] = prediction\n","    xval = np.hstack([xval[:,1:],prediction])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sXPlfRLZ6DpX"},"source":["plt.figure(figsize=(12,5))\n","# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n","plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n","plt.plot(np.arange(look_ahead),dataset[train_size:(train_size+look_ahead)],label=\"test function\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"S_5C1XZF6DpX"},"source":["1000ê°œì˜ ìƒ˜í”Œì´ ìˆë‹¤.\n","íƒ€ì„ìŠ¤íƒ¬í”„ëŠ” 100ê°œì´ë‹¤. ì¦‰ 100 ìˆœê°„ì˜ ë°ì´í„°ê°€ ìˆë‹¤. í•˜ë‚˜ì˜ íƒ€ì„ìŠ¤í…œí”„ëŠ” 10ê°œì˜ ë°±í„° ê¸¸ì´ê°€ ìˆë‹¤. \n","ì…ë ¥ìë£ŒëŠ” 1000 * 100 * 10 \n","ë°°ì¹˜ì‚¬ì´ì¦ˆëŠ” 20ê°œì´ë‹¤.\n","\n","ë°°ì¹˜ì‚¬ì´ì¦ˆë¥¼ ì§€ì •í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, \n","1000ê°œì˜ ìƒ˜í”Œì„ ëª¨ë‘ ì·¨í•œë‹¤."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"GANiwbT36DpX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nkv60Ho8CuLL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mEOOxhpsCY7G"},"source":["## **3. LSTM ëª¨ë¸ í™œìš©í•˜ê¸°**\n","\n","ì•ì„œ ì‚´í´ë³¸ LSTM ë ˆì´ì–´ë¥¼ ì´ìš©í•˜ì—¬ ëª‡ê°€ì§€ ìˆœí™˜ ì‹ ê²½ë§ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ê³ , ê° ëª¨ë¸ì— \"ë‚˜ë¹„ì•¼\" ë™ìš”ë¥¼ í•™ìŠµì‹œì¼œë³´ë©´ì„œ ìì„¸íˆ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."]},{"cell_type":"markdown","metadata":{"id":"kxoDeCG5CY7H"},"source":["---\n","\n","### *ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„*\n","\n","ìˆœí™˜ ì‹ ê²½ë§ì€ ì£¼ë¡œ ìì—°ì–´ ì²˜ë¦¬ì— ë§ì´ ì“°ì´ê¸° ë•Œë¬¸ì— ë¬¸ì¥ í•™ìŠµ ì˜ˆì œê°€ ì¼ë°˜ì ì´ì§€ë§Œ ë³¸ ê°•ì¢Œì—ì„œëŠ” ì•…ë³´ í•™ìŠµì„ í•´ë³´ê² ìŠµë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ” \n","- ìŒê³„ê°€ ë¬¸ì¥ë³´ë‹¤ ë” ì½”ë“œí™” í•˜ê¸° ì‰½ê³ , \n","- ì‹œê³„ì—´ ìë£Œì´ë©°, \n","- ë‚˜ì˜¨ ê²°ê³¼ë¥¼ ì•…ë³´ë¡œ ë³¼ ìˆ˜ ìˆìœ¼ë©°,\n","- ë¬´ì—‡ë³´ë‹¤ ìš°ë¦¬ê°€ í•™ìŠµí•œ ëª¨ë¸ì´ ì—°ì£¼í•˜ëŠ” ê³¡ì„ ë“¤ì–´ë³¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. \n","ì¼ë‹¨ ì‰¬ìš´ ì•…ë³´ì¸ 'ë‚˜ë¹„ì•¼'ë¥¼ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_2.png)\n","\n","ìŒí‘œ ë°‘ì— ê°„ë‹¨í•œ ìŒí‘œì½”ë“œë¥¼ í‘œì‹œí•˜ì˜€ìŠµë‹ˆë‹¤. ì•ŒíŒŒë²³ì€ ìŒê³„ë¥¼ ë‚˜íƒ€ë‚´ë©°, ìˆ«ìëŠ” ìŒì˜ ê¸¸ì´ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n","- c(ë„), d(ë ˆ), e(ë¯¸), f(íŒŒ), g(ì†”), a(ë¼), b(ì‹œ)\n","- 4(4ë¶„ìŒí‘œ), 8(8ë¶„ìŒí‘œ)"]},{"cell_type":"markdown","metadata":{"id":"LflhttcQCY7H"},"source":["---\n","\n","### *ë°ì´í„°ì…‹ ìƒì„±*\n","\n","ë¨¼ì € ë‘ ë§ˆë””ë§Œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. \n","\n","* g8 e8 e4\n","* f8 d8 d4 \n","\n","ì—¬ê¸°ì„œ ìš°ë¦¬ê°€ ì •ì˜í•œ ë¬¸ì œëŒ€ë¡œ 4ê°œ ìŒí‘œ ì…ë ¥ìœ¼ë¡œ ë‹¤ìŒ ì¶œë ¥ ìŒí‘œë¥¼ ì˜ˆì¸¡í•˜ë ¤ë©´, ì•„ë˜ì™€ ê°™ì´ ë°ì´í„°ì…‹ì„ êµ¬ì„±í•©ë‹ˆë‹¤.\n","\n","* g8 e8 e4 f8 **d8** : 1~4ë²ˆì§¸ ìŒí‘œ, **5ë²ˆì§¸** ìŒí‘œ\n","* e8 e4 f8 d8 **d4** : 2~5ë²ˆì§¸ ìŒí‘œ, **6ë²ˆì§¸** ìŒí‘œ\n","\n","6ê°œì˜ ìŒí‘œë¡œëŠ” ìœ„ì™€ ê°™ì´ 2ê°œì˜ ìƒ˜í”Œì´ ë‚˜ì˜µë‹ˆë‹¤. ê° ìƒ˜í”Œì€ 4ê°œì˜ ì…ë ¥ ë°ì´í„°ì™€ 1ê°œì˜ ë¼ë²¨ê°’ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¦‰ 1~4ë²ˆì§¸ ì—´ì€ ì†ì„±(feature)ì´ê³ , 5ë²ˆì§¸ ì—´ì€ í´ë˜ìŠ¤(class)ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ë ‡ê²Œ 4ê°œì”© êµ¬ê°„ì„ ë³´ëŠ” ê²ƒì„ ìœˆë„ìš° í¬ê¸°ê°€ 4ë¼ê³  í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ë¬¸ìì™€ ìˆ«ìë¡œ ëœ ìŒí‘œ(ì½”ë“œ)ë¡œëŠ” ëª¨ë¸ ì…ì¶œë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ê° ì½”ë“œë¥¼ ìˆ«ìë¡œ ë³€í™˜í•  ìˆ˜ ìˆëŠ” ì‚¬ì „ì„ í•˜ë‚˜ ë§Œë“¤ì–´ë´…ë‹ˆë‹¤. ì²«ë²ˆì§¸ ì‚¬ì „ì€ ì½”ë“œë¥¼ ìˆ«ìë¡œ, ë‘ë²ˆì§¸ ì‚¬ì „ì€ ìˆ«ìë¥¼ ì½”ë“œë¡œ ë§Œë“œëŠ” ì½”ë“œì…ë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"TIcD7y5wCY7I"},"source":["code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n","            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n","\n","idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n","            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xjUaQ_YQCY7K"},"source":["ì´ëŸ¬í•œ ì‚¬ì „ì„ ì´ìš©í•´ì„œ ìˆœì°¨ì ì¸ ìŒí‘œë¥¼ ìš°ë¦¬ê°€ ì§€ì •í•œ ìœˆë„ìš° í¬ê¸°ë§Œí¼ ì˜ë¼ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•´ë³´ê² ìŠµë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"GyjnmpV_CY7K"},"source":["import numpy as np\n","\n","def seq2dataset(seq, window_size):\n","    dataset = []\n","    for i in range(len(seq)-window_size):\n","        subset = seq[i:(i+window_size+1)]\n","        dataset.append([code2idx[item] for item in subset])\n","    return np.array(dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yL1tII3ZCY7K"},"source":["seqë¼ëŠ” ë³€ìˆ˜ì— \"ë‚˜ë¹„ì•¼\" ê³¡ ì „ì²´ ìŒí‘œë¥¼ ì €ì¥í•œ ë‹¤ìŒ, seq2dataset() í•¨ìˆ˜ë¥¼ í•˜ì—¬ datasetë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë°ì´í„°ì…‹ì€ ì•ì„œ ì •ì˜í•œ ì‚¬ì „ì— ë”°ë¼ ìˆ«ìë¡œ ë³€í™˜ë˜ì–´ ìƒì„±ë©ë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"id":"Ekq7WJAxCY7L"},"source":["seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n","       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n","       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n","       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']\n","\n","dataset = seq2dataset(seq, window_size = 4)\n","\n","print(dataset.shape)\n","print(dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Ev89nmsCY7S"},"source":["---\n","\n","### *í•™ìŠµ ê³¼ì •*\n","\n","\"ë‚˜ë¹„ì•¼\"ë…¸ë˜ëŠ” ìš°ë¦¬ì—ê²Œ ë„ˆë¬´ë‚˜ ìµìˆ™í•œ ë…¸ë˜ì…ë‹ˆë‹¤. ë§Œì•½ ì˜†ì‚¬ëŒì´ \"ë‚˜ë¹„ì•¼~ ë‚˜\"ê¹Œì§€ë§Œ ë¶ˆëŸ¬ë„ ë‚˜ë¨¸ì§€ë¥¼ ì´ì–´ì„œ ë‹¤ ë¶€ë¥¼ ìˆ˜ ìˆì„ ì •ë„ë¡œ ë§ì´ì£ . ì´ë ‡ê²Œ ì²« 4ê°œ ìŒí‘œë¥¼ ì…ë ¥í•˜ë©´ ë‚˜ë¨¸ì§€ë¥¼ ì—°ì£¼í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì •ì˜í•œ ë¬¸ì œë¥¼ í’€ê¸° ìœ„í•´ ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì•¼ í•©ë‹ˆë‹¤. í•™ìŠµ ì‹œí‚¤ëŠ” ë°©ì‹ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n","\n","- íŒŒë€ìƒ‰ ë°•ìŠ¤ê°€ ì…ë ¥ê°’ì´ê³ , ë¹¨ê°„ìƒ‰ ë°•ìŠ¤ê°€ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ì¶œë ¥ê°’ì…ë‹ˆë‹¤. \n","- 1~4ë²ˆì§¸ ìŒí‘œë¥¼ ë°ì´í„°ë¡œ 5ë²ˆì§¸ ìŒí‘œë¥¼ ë¼ë²¨ê°’ìœ¼ë¡œ í•™ìŠµì„ ì‹œí‚µë‹ˆë‹¤.\n","- ë‹¤ìŒì—ëŠ” 2~5ë²ˆì§¸ ìŒí‘œë¥¼ ë°ì´í„°ë¡œ 6ë²ˆì§¸ ìŒí‘œë¥¼ ë¼ë²¨ê°’ìœ¼ë¡œ í•™ìŠµì„ ì‹œí‚µë‹ˆë‹¤.\n","- ì´í›„ í•œ ìŒí‘œì”© ë„˜ì–´ê°€ë©´ì„œ ë…¸ë˜ ëê¹Œì§€ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_5.png)"]},{"cell_type":"markdown","metadata":{"id":"-Pqvof71a868"},"source":["---\n","### *ì˜ˆì¸¡ ê³¼ì •*\n","\n","ì˜ˆì¸¡ì€ ë‘ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ í•´ë³´ê² ìŠµë‹ˆë‹¤. `í•œ ìŠ¤í… ì˜ˆì¸¡`ê³¼ `ê³¡ ì „ì²´ ì˜ˆì¸¡`ì…ë‹ˆë‹¤. \n"]},{"cell_type":"markdown","metadata":{"id":"gkYjwfNma-Gz"},"source":["#### í•œ ìŠ¤í… ì˜ˆì¸¡\n","\n","í•œ ìŠ¤í… ì˜ˆì¸¡ì´ë€ ì‹¤ì œ ìŒí‘œ 4ê°œë¥¼ ì…ë ¥í•˜ì—¬ ë‹¤ìŒ ìŒí‘œ 1ê°œë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì„ ë°˜ë³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ ë°©ë²•ì—ì„œëŠ” ëª¨ë¸ì˜ ì…ë ¥ê°’ìœ¼ë¡œëŠ” í•­ìƒ ì‹¤ì œ ìŒí‘œê°€ ë“¤ì–´ê°‘ë‹ˆë‹¤.\n","- ëª¨ë¸ì— t0, t1, t2, t3ë¥¼ ì…ë ¥í•˜ë©´ y0 ì¶œë ¥ì´ ë‚˜ì˜µë‹ˆë‹¤. \n","- ëª¨ë¸ì— t1, t2, t3, t4ë¥¼ ì…ë ¥í•˜ë©´ y1 ì¶œë ¥ì´ ë‚˜ì˜µë‹ˆë‹¤.\n","- ëª¨ë¸ì— t2, t3, t4, t5ë¥¼ ì…ë ¥í•˜ë©´ y2 ì¶œë ¥ì´ ë‚˜ì˜µë‹ˆë‹¤.\n","- ì´ ê³¼ì •ì„ y49 ì¶œë ¥ê¹Œì§€ ë°˜ë³µí•©ë‹ˆë‹¤. \n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_6.png)"]},{"cell_type":"markdown","metadata":{"id":"vB6d_3E8CY7T"},"source":["#### ê³¡ ì „ì²´ ì˜ˆì¸¡\n","\n","ê³¡ ì „ì²´ ì˜ˆì¸¡ì´ë€ ì…ë ¥ëœ ì´ˆê°€ 4ê°œ ìŒí‘œë§Œì„ ì…ë ¥ìœ¼ë¡œ ê³¡ ì „ì²´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ˆë°˜ë¶€ê°€ ì§€ë‚˜ë©´, ì˜ˆì¸¡ê°’ë§Œìœ¼ë¡œ ëª¨ë¸ì— ì…ë ¥ë˜ì–´ ë‹¤ìŒ ì˜ˆì¸¡ê°’ì´ ë‚˜ì˜¤ëŠ” ì‹ì…ë‹ˆë‹¤. ê·¸ì•¼ë§ë¡œ \"ë‚˜ë¹„ì•¼~ ë‚˜\"ê¹Œì§€ ì•Œë ¤ì£¼ë©´ ë‚˜ë¨¸ì§€ê¹Œì§€ ëª¨ë‘ ì—°ì£¼ë¥¼ í•˜ëŠ” ê²ƒì´ì£ . ë§Œì•½ ì¤‘ê°„ì— í‹€ë¦° ë¶€ë¶„ì´ ìƒê¸´ë‹¤ë©´, ì´í›„ ìŒì •, ë°•ìëŠ” ëª¨ë‘ ì´ìƒí•˜ê²Œ ë  ê°€ëŠ¥ì„±ì´ ë§ìŠµë‹ˆë‹¤. ì˜ˆì¸¡ ì˜¤ë¥˜ê°€ ëˆ„ì ë˜ëŠ” ê²ƒì´ê² ì£ .\n","\n","- ëª¨ë¸ì— t0, t1, t2, t3ë¥¼ ì…ë ¥í•˜ë©´ y0 ì¶œë ¥ì´ ë‚˜ì˜µë‹ˆë‹¤.\n","- ì˜ˆì¸¡ê°’ì¸ y0ë¥¼ t4ë¼ê³  ê°€ì •í•˜ê³ , ëª¨ë¸ì— t1, t2, t3, t4ì„ ì…ë ¥í•˜ë©´ y1 ì¶œë ¥ì´ ë‚˜ì˜µë‹ˆë‹¤.\n","- ì˜ˆì¸¡ê°’ì¸ y1ì„ t5ë¼ê³  ê°€ì •í•˜ê³ , ëª¨ë¸ì— t2, t3, t4(ì˜ˆì¸¡ê°’), t5(ì˜ˆì¸¡ê°’)ì„ ì…ë ¥í•˜ë©´ y2 ì¶œë ¥ì´ ë‚˜ì˜µë‹ˆë‹¤.\n","- ì´ ê³¼ì •ì„ y49 ì¶œë ¥ê¹Œì§€ ë°˜ë³µí•©ë‹ˆë‹¤.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_7.png)"]},{"cell_type":"markdown","metadata":{"id":"VtPWC0yjCY7T"},"source":["---\n","\n","### *ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  ëª¨ë¸*\n","\n","ì•ì„œ ìƒì„±í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ ë¨¼ì € ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  ëª¨ë¸ì„ í•™ìŠµì‹œì¼œë³´ê² ìŠµë‹ˆë‹¤. Dense ë ˆì´ì–´ 3ê°œë¡œ êµ¬ì„±í•˜ì˜€ê³ , ì…ë ¥ ì†ì„±ì´ 4ê°œì´ê³  ì¶œë ¥ì´ 12ê°œ(one_hot_vec_size=12)ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"id":"ii9tcyUTCY7U"},"source":["one_hot_vec_size = len(code2idx)\n","\n","model = Sequential()\n","model.add(Dense(128, input_dim=4, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fXkQ9fsKCY7U"},"source":["\"ë‚˜ë¹„ì•¼\" ì•…ë³´ë¥¼ ì´ ëª¨ë¸ì„ í•™ìŠµí•  ê²½ìš° ë‹¤ìŒ ê·¸ë¦¼ê³¼ ê°™ì´ ìˆ˜í–‰ë©ë‹ˆë‹¤. 4ê°œì˜ ìŒí‘œë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³ , ê·¸ ë‹¤ìŒ ìŒí‘œê°€ ë¼ë²¨ê°’ìœ¼ë¡œ ì§€ì •ë©ë‹ˆë‹¤. ì´ ê³¼ì •ì„ ê³¡ì´ ë§ˆì¹  ë•Œê¹Œì§€ ë°˜ë³µí•˜ê²Œ ë©ë‹ˆë‹¤."]},{"cell_type":"markdown","metadata":{"id":"63BvmS0FCY7U"},"source":["![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_train_MLP.png)"]},{"cell_type":"markdown","metadata":{"id":"qfRP2sN5CY7V"},"source":["#### ì†ŒìŠ¤ì½”ë“œ\n","\n","ì „ì²´ ì†ŒìŠ¤ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"id":"m7cGftucCY7V"},"source":["# 0. ì‚¬ìš©í•  íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import np_utils\n","import numpy as np\n","\n","# ëœë¤ì‹œë“œ ê³ ì •ì‹œí‚¤ê¸°\n","np.random.seed(5)\n","\n","# ì†ì‹¤ ì´ë ¥ í´ë˜ìŠ¤ ì •ì˜\n","class LossHistory(keras.callbacks.Callback):\n","    def init(self):\n","        self.losses = []\n","        \n","    def on_epoch_end(self, batch, logs={}):\n","        self.losses.append(logs.get('loss'))\n","\n","# ë°ì´í„°ì…‹ ìƒì„± í•¨ìˆ˜        \n","def seq2dataset(seq, window_size):\n","    dataset = []\n","    for i in range(len(seq)-window_size):\n","        subset = seq[i:(i+window_size+1)]\n","        dataset.append([code2idx[item] for item in subset])\n","    return np.array(dataset)\n","\n","# 1. ë°ì´í„° ì¤€ë¹„í•˜ê¸°\n","\n","# ì½”ë“œ ì‚¬ì „ ì •ì˜\n","\n","code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n","            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n","\n","idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n","            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}\n","\n","# ì‹œí€€ìŠ¤ ë°ì´í„° ì •ì˜\n","\n","seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n","       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n","       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n","       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']\n","\n","# 2. ë°ì´í„°ì…‹ ìƒì„±í•˜ê¸°\n","dataset = seq2dataset(seq, window_size = 4)\n","\n","print(dataset.shape)\n","print(dataset)\n","\n","# ì…ë ¥(X)ê³¼ ì¶œë ¥(Y) ë³€ìˆ˜ë¡œ ë¶„ë¦¬í•˜ê¸°\n","x_train = dataset[:,0:4]\n","y_train = dataset[:,4]\n","\n","max_idx_value = 13\n","\n","# ì…ë ¥ê°’ ì •ê·œí™” ì‹œí‚¤ê¸°\n","x_train = x_train / float(max_idx_value)\n","\n","# ë¼ë²¨ê°’ì— ëŒ€í•œ one-hot ì¸ì½”ë”© ìˆ˜í–‰\n","y_train = np_utils.to_categorical(y_train)\n","\n","one_hot_vec_size = y_train.shape[1]\n","\n","print(\"one hot encoding vector size is \", one_hot_vec_size)\n","\n","# 3. ëª¨ë¸ êµ¬ì„±í•˜ê¸°\n","model = Sequential()\n","model.add(Dense(128, input_dim=4, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))\n","\n","# 4. ëª¨ë¸ í•™ìŠµê³¼ì • ì„¤ì •í•˜ê¸°\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","history = LossHistory() # ì†ì‹¤ ì´ë ¥ ê°ì²´ ìƒì„±\n","history.init()\n","\n","# 5. ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸°\n","model.fit(x_train, y_train, epochs=2000, batch_size=10, verbose=2, callbacks=[history])\n","    \n","# 6. í•™ìŠµê³¼ì • ì‚´í´ë³´ê¸°\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.plot(history.losses)\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train'], loc='upper left')\n","plt.show()\n","\n","# 7. ëª¨ë¸ í‰ê°€í•˜ê¸°\n","scores = model.evaluate(x_train, y_train)\n","print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n","\n","# 8. ëª¨ë¸ ì‚¬ìš©í•˜ê¸°\n","\n","pred_count = 50 # ìµœëŒ€ ì˜ˆì¸¡ ê°œìˆ˜ ì •ì˜\n","\n","# í•œ ìŠ¤í… ì˜ˆì¸¡\n","\n","seq_out = ['g8', 'e8', 'e4', 'f8']\n","pred_out = model.predict(x_train)\n","\n","for i in range(pred_count):\n","    idx = np.argmax(pred_out[i]) # one-hot ì¸ì½”ë”©ì„ ì¸ë±ìŠ¤ ê°’ìœ¼ë¡œ ë³€í™˜\n","    seq_out.append(idx2code[idx]) # seq_outëŠ” ìµœì¢… ì•…ë³´ì´ë¯€ë¡œ ì¸ë±ìŠ¤ ê°’ì„ ì½”ë“œë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥\n","    \n","print(\"one step prediction : \", seq_out)\n","\n","# ê³¡ ì „ì²´ ì˜ˆì¸¡\n","\n","seq_in = ['g8', 'e8', 'e4', 'f8']\n","seq_out = seq_in\n","seq_in = [code2idx[it] / float(max_idx_value) for it in seq_in] # ì½”ë“œë¥¼ ì¸ë±ìŠ¤ê°’ìœ¼ë¡œ ë³€í™˜\n","\n","for i in range(pred_count):\n","    sample_in = np.array(seq_in)\n","    sample_in = np.reshape(sample_in, (1, 4)) # batch_size, feature\n","    pred_out = model.predict(sample_in)\n","    idx = np.argmax(pred_out)\n","    seq_out.append(idx2code[idx])\n","    seq_in.append(idx / float(max_idx_value))\n","    seq_in.pop(0)\n","\n","print(\"full song prediction : \", seq_out)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C7H_l6WqCY7X"},"source":["í•œ ìŠ¤í… ì˜ˆì¸¡ ê²°ê³¼ì™€ ê³¡ ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì•…ë³´ë¡œ ê·¸ë ¤ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ ì¤‘ í‹€ë¦° ë¶€ë¶„ì„ ë¹¨ê°„ìƒ‰ ë°•ìŠ¤ë¡œ í‘œì‹œí•´ë´¤ìŠµë‹ˆë‹¤. ì´ 50ê°œ ì˜ˆì¸¡ ì¤‘ 4ê°œê°€ í‹€ë ¤ì„œ 92%ì˜ ì •í™•ë„ê°€ ë‚˜ì™”ìŠµë‹ˆë‹¤. ì¤‘ê°„ì— í‹€ë¦° ë¶€ë¶„ì´ ìƒê¸°ë©´ ê³¡ ì „ì²´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° ìˆì–´ì„œëŠ” ê·¸ë¦¬ ì¢‹ì€ ì„±ëŠ¥ì´ ë‚˜ì˜¤ì§€ ì•ŠìŠµë‹ˆë‹¤.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_MLP_song.png)\n","\n","ìœ„ ì•…ë³´ë¡œ ì—°ì£¼í•œ ê³¡ì€ ì•„ë˜ ë§í¬ì—ì„œ ë‹¤ìš´ë¡œë“œ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","* [http://tykimos.github.io/warehouse/2017-4-9-MLP_one_step_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-MLP_one_step_prediction.mp3)\n","* [http://tykimos.github.io/warehouse/2017-4-9-MLP_full_song_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-MLP_full_song_prediction.mp3)"]},{"cell_type":"markdown","metadata":{"id":"X1BCtlleCY7Y"},"source":["---\n","\n","### *ê¸°ë³¸ LSTM ëª¨ë¸*\n","\n","ì´ë²ˆì—ëŠ” ê°„ë‹¨í•œ ê¸°ë³¸ LSTM ëª¨ë¸ë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ê² ìŠµë‹ˆë‹¤. ëª¨ë¸ êµ¬ì„±ì€ ë‹¤ìŒê³¼ ê°™ì´ í•˜ì˜€ìŠµë‹ˆë‹¤.\n","- 128 ë©”ëª¨ë¦¬ ì…€ì„ ê°€ì§„ LSTM ë ˆì´ì–´ 1ê°œì™€ Dense ë ˆì´ì–´ë¡œ êµ¬ì„±\n","- ì…ë ¥ì€ ìƒ˜í”Œì´ 50ê°œ, íƒ€ì„ìŠ¤í…ì´ 4ê°œ, ì†ì„±ì´ 1ê°œë¡œ êµ¬ì„±\n","- ìƒíƒœìœ ì§€(stateful) ëª¨ë“œ ë¹„í™œì„±í™”\n","\n","ì¼€ë¼ìŠ¤ì—ì„œëŠ” ì•„ë˜ì™€ ê°™ì´ LSTMì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"UcWxY1whCY7Z"},"source":["model = Sequential()\n","model.add(LSTM(128, input_shape = (4, 1)))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4pVDR15RCY7Z"},"source":["LSTMì„ ì œëŒ€ë¡œ í™œìš©í•˜ê¸° ìœ„í•´ì„œëŠ” `ìƒíƒœìœ ì§€ ëª¨ë“œ`, `ë°°ì¹˜ì‚¬ì´ì¦ˆ`, `íƒ€ì„ìŠ¤í…`, `ì†ì„±`ì— ëŒ€í•œ ê°œë…ì— ì´í•´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë³¸ ì ˆì—ì„œëŠ” `íƒ€ì„ìŠ¤í…`ì— ëŒ€í•´ì„œ ë¨¼ì € ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. `íƒ€ì„ìŠ¤í…`ì´ë€ í•˜ë‚˜ì˜ ìƒ˜í”Œì— í¬í•¨ëœ ì‹œí€€ìŠ¤ ê°œìˆ˜ì…ë‹ˆë‹¤. ì´ëŠ” ì•ì„œ ì‚´í´ë³¸ \"input_length\"ì™€ ë™ì¼í•©ë‹ˆë‹¤. í˜„ì¬ ë¬¸ì œì—ì„œëŠ” ë§¤ ìƒ˜í”Œë§ˆë‹¤ 4ê°œì˜ ê°’ì„ ì…ë ¥í•˜ë¯€ë¡œ íƒ€ì„ìŠ¤í…ì´ 4ê°œë¡œ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦‰ ìœˆë„ìš° í¬ê¸°ì™€ ë™ì¼í•˜ê²Œ íƒ€ì„ìŠ¤í…ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ë©ë‹ˆë‹¤. `ì†ì„±`ì— ëŒ€í•´ì„œëŠ” ë‚˜ì¤‘ì— ì•Œì•„ë³´ê² ì§€ë§Œ, ì…ë ¥ë˜ëŠ” ìŒí‘œ 1ê°œë‹¹ í•˜ë‚˜ì˜ ì¸ë±ìŠ¤ ê°’ì„ ì…ë ¥í•˜ë¯€ë¡œ ì†ì„±ì´ 1ê°œì…ë‹ˆë‹¤. ë‚˜ì¤‘ì— ì´ `ì†ì„±`ì˜ ê°œìˆ˜ë¥¼ ë‹¤ë¥´ê²Œ í•´ì„œ í…ŒìŠ¤íŠ¸ í•´ë³´ê² ìŠµë‹ˆë‹¤. ì¸ìë¡œ \"input_shape = (4, 1)'ê³¼ \"input_dim = 1, input_length = 4\"ëŠ” ë™ì¼í•©ë‹ˆë‹¤. ì„¤ì •í•œ LSTM ëª¨ë¸ì— ë”°ë¼ ì…ë ¥í•  ë°ì´í„°ì…‹ë„ ìƒ˜í”Œ ìˆ˜, íƒ€ì„ìŠ¤í… ìˆ˜, ì†ì„± ìˆ˜ í˜•ì‹ìœ¼ë¡œ ë§ì¶”ì–´ì•¼ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì•ì„œ êµ¬ì„±í•œ x_trainë¥¼ ì•„ë˜ì™€ ê°™ì´ í˜•ì‹ì„ ë³€í™˜í•©ë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"VAz-8PiUCY7a"},"source":["x_train = np.reshape(x_train, (50, 4, 1)) # ìƒ˜í”Œ ìˆ˜, íƒ€ì„ìŠ¤í… ìˆ˜, ì†ì„± ìˆ˜"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B11VhWLBCY7a"},"source":["ì´ ëª¨ë¸ë¡œ ì•…ë³´ë¥¼ í•™ìŠµí•  ê²½ìš°, ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  ëª¨ë¸ê³¼ ë™ì¼í•˜ê²Œ 4ê°œì˜ ìŒí‘œë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³ , ê·¸ ë‹¤ìŒ ìŒí‘œê°€ ë¼ë²¨ê°’ìœ¼ë¡œ ì§€ì •ë©ë‹ˆë‹¤. ì´ ê³¼ì •ì„ ê³¡ì´ ë§ˆì¹  ë•Œê¹Œì§€ ë°˜ë³µí•˜ê²Œ ë©ë‹ˆë‹¤. ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  ëª¨ë¸ê³¼ ì°¨ì´ì ì´ ìˆë‹¤ë©´, ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  ëª¨ë¸ì—ì„œëŠ” 4ê°œì˜ ìŒí‘œê°€ 4ê°œì˜ ì†ì„±ìœ¼ë¡œ ì…ë ¥ë˜ê³ , LSTMì—ì„œëŠ” 4ê°œì˜ ìŒí‘œê°€ 4ê°œì˜ ì‹œí€€ìŠ¤ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤. ì—¬ê¸°ì„œ ì†ì„±ì€ 1ê°œì…ë‹ˆë‹¤."]},{"cell_type":"markdown","metadata":{"id":"BtZV5CQVCY7b"},"source":["![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_train_LSTM.png)"]},{"cell_type":"markdown","metadata":{"id":"p1LT7ckDCY7b"},"source":["#### ì†ŒìŠ¤ì½”ë“œ\n","\n","ì „ì²´ ì†ŒìŠ¤ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"id":"s-cCGrsECY7c"},"source":["# 0. ì‚¬ìš©í•  íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n","import keras\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.utils import np_utils\n","\n","# ëœë¤ì‹œë“œ ê³ ì •ì‹œí‚¤ê¸°\n","np.random.seed(5)\n","\n","# ì†ì‹¤ ì´ë ¥ í´ë˜ìŠ¤ ì •ì˜\n","class LossHistory(keras.callbacks.Callback):\n","    def init(self):\n","        self.losses = []\n","        \n","    def on_epoch_end(self, batch, logs={}):\n","        self.losses.append(logs.get('loss'))\n","\n","# ë°ì´í„°ì…‹ ìƒì„± í•¨ìˆ˜\n","def seq2dataset(seq, window_size):\n","    dataset = []\n","    for i in range(len(seq)-window_size):\n","        subset = seq[i:(i+window_size+1)]\n","        dataset.append([code2idx[item] for item in subset])\n","    return np.array(dataset)\n","\n","# 1. ë°ì´í„° ì¤€ë¹„í•˜ê¸°\n","        \n","# ì½”ë“œ ì‚¬ì „ ì •ì˜\n","\n","code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n","            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n","\n","idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n","            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}\n","\n","# ì‹œí€€ìŠ¤ ë°ì´í„° ì •ì˜\n","\n","seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n","       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n","       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n","       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']\n","\n","# 2. ë°ì´í„°ì…‹ ìƒì„±í•˜ê¸°\n","\n","dataset = seq2dataset(seq, window_size = 4)\n","\n","print(dataset.shape)\n","\n","# ì…ë ¥(X)ê³¼ ì¶œë ¥(Y) ë³€ìˆ˜ë¡œ ë¶„ë¦¬í•˜ê¸°\n","x_train = dataset[:,0:4]\n","y_train = dataset[:,4]\n","\n","max_idx_value = 13\n","\n","# ì…ë ¥ê°’ ì •ê·œí™” ì‹œí‚¤ê¸°\n","x_train = x_train / float(max_idx_value)\n","\n","# ì…ë ¥ì„ (ìƒ˜í”Œ ìˆ˜, íƒ€ì…ìŠ¤í…, íŠ¹ì„± ìˆ˜)ë¡œ í˜•íƒœ ë³€í™˜\n","x_train = np.reshape(x_train, (50, 4, 1))\n","\n","# ë¼ë²¨ê°’ì— ëŒ€í•œ one-hot ì¸ì½”ë”© ìˆ˜í–‰\n","y_train = np_utils.to_categorical(y_train)\n","\n","one_hot_vec_size = y_train.shape[1]\n","\n","print(\"one hot encoding vector size is \", one_hot_vec_size)\n","\n","# 3. ëª¨ë¸ êµ¬ì„±í•˜ê¸°\n","model = Sequential()\n","model.add(LSTM(128, input_shape = (4, 1)))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))\n","\n","# 4. ëª¨ë¸ í•™ìŠµê³¼ì • ì„¤ì •í•˜ê¸°\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","history = LossHistory() # ì†ì‹¤ ì´ë ¥ ê°ì²´ ìƒì„±\n","history.init()\n","\n","# 5. ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸°\n","model.fit(x_train, y_train, epochs=2000, batch_size=14, verbose=2, callbacks=[history])\n","\n","# 6. í•™ìŠµê³¼ì • ì‚´í´ë³´ê¸°\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.plot(history.losses)\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train'], loc='upper left')\n","plt.show()\n","\n","# 7. ëª¨ë¸ í‰ê°€í•˜ê¸°\n","scores = model.evaluate(x_train, y_train)\n","print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n","\n","# 8. ëª¨ë¸ ì‚¬ìš©í•˜ê¸°\n","\n","pred_count = 50 # ìµœëŒ€ ì˜ˆì¸¡ ê°œìˆ˜ ì •ì˜\n","\n","# í•œ ìŠ¤í… ì˜ˆì¸¡\n","\n","seq_out = ['g8', 'e8', 'e4', 'f8']\n","pred_out = model.predict(x_train)\n","\n","for i in range(pred_count):\n","    idx = np.argmax(pred_out[i]) # one-hot ì¸ì½”ë”©ì„ ì¸ë±ìŠ¤ ê°’ìœ¼ë¡œ ë³€í™˜\n","    seq_out.append(idx2code[idx]) # seq_outëŠ” ìµœì¢… ì•…ë³´ì´ë¯€ë¡œ ì¸ë±ìŠ¤ ê°’ì„ ì½”ë“œë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥\n","    \n","print(\"one step prediction : \", seq_out)\n","\n","# ê³¡ ì „ì²´ ì˜ˆì¸¡\n","\n","seq_in = ['g8', 'e8', 'e4', 'f8']\n","seq_out = seq_in\n","seq_in = [code2idx[it] / float(max_idx_value) for it in seq_in] # ì½”ë“œë¥¼ ì¸ë±ìŠ¤ê°’ìœ¼ë¡œ ë³€í™˜\n","\n","for i in range(pred_count):\n","    sample_in = np.array(seq_in)\n","    sample_in = np.reshape(sample_in, (1, 4, 1)) # ìƒ˜í”Œ ìˆ˜, íƒ€ì…ìŠ¤í… ìˆ˜, ì†ì„± ìˆ˜\n","    pred_out = model.predict(sample_in)\n","    idx = np.argmax(pred_out)\n","    seq_out.append(idx2code[idx])\n","    seq_in.append(idx / float(max_idx_value))\n","    seq_in.pop(0)\n","\n","print(\"full song prediction : \", seq_out)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a8ZGpgd4CY7j"},"source":["í•œ ìŠ¤í… ì˜ˆì¸¡ ê²°ê³¼ì™€ ê³¡ ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì•…ë³´ë¡œ ê·¸ë ¤ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ ì¤‘ í‹€ë¦° ë¶€ë¶„ì„ ë¹¨ê°„ìƒ‰ ë°•ìŠ¤ë¡œ í‘œì‹œí•´ë´¤ìŠµë‹ˆë‹¤. ì´ 50ê°œ ì˜ˆì¸¡ ì¤‘ 4ê°œê°€ í‹€ë ¤ì„œ 92%ì˜ ì •í™•ë„ê°€ ë‚˜ì™”ìŠµë‹ˆë‹¤. ì¤‘ê°„ì— í‹€ë¦­ ë¶€ë¶„ì´ ìƒê¸°ë©´ ê³¡ ì „ì²´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° ìˆì–´ì„œëŠ” ê·¸ë¦¬ ì¢‹ì€ ì„±ëŠ¥ì´ ë‚˜ì˜¤ì§€ ì•ŠìŠµë‹ˆë‹¤.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_LSTM_song.png)\n","\n","ìœ„ ì•…ë³´ë¡œ ì—°ì£¼í•œ ê³¡ì€ ì•„ë˜ ë§í¬ì—ì„œ ë‹¤ìš´ë¡œë“œ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","* [http://tykimos.github.io/warehouse/2017-4-9-Stateless_LSTM_one_step_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateless_LSTM_one_step_prediction.mp3)\n","* [http://tykimos.github.io/warehouse/2017-4-9-Stateless_LSTM_full_song_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateless_LSTM_full_song_prediction.mp3)"]},{"cell_type":"markdown","metadata":{"id":"E99p3YwqCY7j"},"source":["---\n","\n","### *ìƒíƒœìœ ì§€ LSTM ëª¨ë¸*\n","\n","ì´ë²ˆì—ëŠ” ìƒíƒœìœ ì§€(Stateful) LSTM ëª¨ë¸ì— ëŒ€í•´ì„œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ `ìƒíƒœìœ ì§€`ë¼ëŠ” ê²ƒì€ í˜„ì¬ í•™ìŠµëœ ìƒíƒœê°€ ë‹¤ìŒ í•™ìŠµ ì‹œ ì´ˆê¸° ìƒíƒœë¡œ ì „ë‹¬ëœë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. \n","\n","    ìƒíƒœìœ ì§€ ëª¨ë“œì—ì„œëŠ” í˜„ì¬ ìƒ˜í”Œì˜ í•™ìŠµ ìƒíƒœê°€ ë‹¤ìŒ ìƒ˜í”Œì˜ ì´ˆê¸° ìƒíƒœë¡œ ì „ë‹¬ëœë‹¤.\n","    \n","ê¸´ ì‹œí€€ë“œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ë•Œ, LSTM ëª¨ë¸ì€ ìƒíƒœìœ ì§€ ëª¨ë“œì—ì„œ ê·¸ ì§„ê°€ë¥¼ ë°œíœ˜í•©ë‹ˆë‹¤. ê¸´ ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ìƒ˜í”Œ ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ í•™ìŠµí•˜ë”ë¼ë„ LSTM ë‚´ë¶€ì ìœ¼ë¡œ ê¸°ì–µí•  ê²ƒì€ ê¸°ì–µí•˜ê³  ë²„ë¦´ ê²ƒì€ ë²„ë ¤ì„œ ê¸°ì–µí•´ì•¼í•  ì¤‘ìš”í•œ ì •ë³´ë§Œ ì´ì–´ê°ˆ ìˆ˜ ìˆë„ë¡ ìƒíƒœê°€ ìœ ì§€ë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ìƒíƒœìœ ì§€ LSTM ëª¨ë¸ì„ ìƒì„±í•˜ê¸° ìœ„í•´ì„œëŠ” LSTM ë ˆì´ì–´ ìƒì„± ì‹œ, stateful=Trueë¡œ ì„¤ì •í•˜ë©´ ë©ë‹ˆë‹¤. ë˜í•œ ìƒíƒœìœ ì§€ ëª¨ë“œì—ì„œëŠ” ì…ë ¥í˜•íƒœë¥¼ batch_input_shape = (ë°°ì¹˜ì‚¬ì´ì¦ˆ, íƒ€ì„ìŠ¤í…, ì†ì„±)ìœ¼ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤. ìƒíƒœìœ ì§€ ëª¨ë“œì—ì„œ ë°°ì¹˜ì‚¬ì´ì¦ˆ ê°œë…ì€ ì¡°ê¸ˆ ì–´ë ¤ìš°ë¯€ë¡œ ë‹¤ìŒ ì¥ì—ì„œ ë‹¤ë£¨ê¸°ë¡œ í•˜ê² ìŠµë‹ˆë‹¤. "]},{"cell_type":"code","metadata":{"collapsed":true,"id":"LU3Sa098CY7k"},"source":["model = Sequential()\n","model.add(LSTM(128, batch_input_shape = (1, 4, 1), stateful=True))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MGMRGhiPCY7k"},"source":["ìƒíƒœìœ ì§€ ëª¨ë“œì—ì„œëŠ” ëª¨ë¸ í•™ìŠµ ì‹œì— `ìƒíƒœ ì´ˆê¸°í™”`ì— ëŒ€í•œ ê³ ë¯¼ì´ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬ ìƒ˜í”Œ í•™ìŠµ ìƒíƒœê°€ ë‹¤ìŒ ìƒ˜í”Œ í•™ìŠµì˜ ì´ˆê¸°ìƒíƒœë¡œ ì „ë‹¬ë˜ëŠ” ì‹ì¸ë°, í˜„ì¬ ìƒ˜í”Œê³¼ ë‹¤ìŒ ìƒ˜í”Œ ê°„ì˜ ìˆœì°¨ì ì¸ ê´€ê³„ê°€ ì—†ì„ ê²½ìš°ì—ëŠ” ìƒíƒœê°€ ìœ ì§€ë˜ì§€ ì•Šê³  ì´ˆê¸°í™”ê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ìŒ ìƒí™©ì´ ì´ëŸ¬í•œ ê²½ìš°ì— í•´ë‹¹ë©ë‹ˆë‹¤.\n","\n","- ë§ˆì§€ë§‰ ìƒ˜í”Œ í•™ìŠµì´ ë§ˆì¹˜ê³ , ìƒˆë¡œìš´ ì—í¬í¬ ìˆ˜í–‰ ì‹œì—ëŠ” ìƒˆë¡œìš´ ìƒ˜í”Œ í•™ìŠµì„ í•´ì•¼í•˜ë¯€ë¡œ ìƒíƒœ ì´ˆê¸°í™” í•„ìš”\n","- í•œ ì—í¬í¬ ì•ˆì— ì—¬ëŸ¬ ì‹œí€€ìŠ¤ ë°ì´í„° ì„¸íŠ¸ê°€ ìˆì„ ê²½ìš°, ìƒˆë¡œìš´ ì‹œí€€ìŠ¤ ë°ì´í„° ì„¸íŠ¸ë¥¼ í•™ìŠµ ì „ì— ìƒíƒœ ì´ˆê¸°í™” í•„ìš”\n","\n","í˜„ì¬ ì½”ë“œì—ì„œëŠ” í•œ ê³¡ì„ ê°€ì§€ê³  ê³„ì† í•™ìŠµì„ ì‹œí‚¤ê³  ìˆìœ¼ë¯€ë¡œ ìƒˆë¡œìš´ ì—í¬í¬ ì‹œì‘ ì‹œì—ë§Œ ìƒíƒœ ì´ˆê¸°í™”ë¥¼ ìˆ˜í–‰í•˜ë©´ ë©ë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"xIIS-eBxCY7k"},"source":["num_epochs = 2000\n","\n","for epoch_idx in range(num_epochs):\n","    print ('epochs : ' + str(epoch_idx) )\n","    model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2, shuffle=False) # 50 is X.shape[0]\n","    model.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E4eACKLGCY7k"},"source":["ì•„ë˜ ê·¸ë¦¼ì€ ì´ ëª¨ë¸ë¡œ ì•…ë³´ë¥¼ í•™ìŠµí•  ê²½ìš°ë¥¼ ë‚˜íƒ€ë‚¸ ê²ƒì…ë‹ˆë‹¤. ê±°ì˜ ê¸°ë³¸ LSTM ëª¨ë¸ê³¼ ë™ì¼í•˜ì§€ë§Œ í•™ìŠµëœ ìƒíƒœê°€ ë‹¤ìŒ ìƒ˜í”Œ í•™ìŠµ ì‹œì— ì´ˆê¸° ìƒíƒœë¡œ ì…ë ¥ë˜ëŠ” ê²ƒì„ ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."]},{"cell_type":"markdown","metadata":{"id":"5hdOKBX6CY7k"},"source":["![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_train_stateful_LSTM.png)"]},{"cell_type":"markdown","metadata":{"id":"rk_EQS1vCY7l"},"source":["#### ì†ŒìŠ¤ì½”ë“œ\n","\n","ì „ì²´ ì†ŒìŠ¤ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"id":"S9dXUXO1CY7l"},"source":["# 0. ì‚¬ìš©í•  íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n","import keras\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM\n","from keras.utils import np_utils\n","\n","# ëœë¤ì‹œë“œ ê³ ì •ì‹œí‚¤ê¸°\n","np.random.seed(5)\n","\n","# ì†ì‹¤ ì´ë ¥ í´ë˜ìŠ¤ ì •ì˜\n","class LossHistory(keras.callbacks.Callback):\n","    def init(self):\n","        self.losses = []\n","        \n","    def on_epoch_end(self, batch, logs={}):\n","        self.losses.append(logs.get('loss'))\n","\n","# ë°ì´í„°ì…‹ ìƒì„± í•¨ìˆ˜\n","def seq2dataset(seq, window_size):\n","    dataset = []\n","    for i in range(len(seq)-window_size):\n","        subset = seq[i:(i+window_size+1)]\n","        dataset.append([code2idx[item] for item in subset])\n","    return np.array(dataset)        \n","\n","# 1. ë°ì´í„° ì¤€ë¹„í•˜ê¸°\n","\n","# ì½”ë“œ ì‚¬ì „ ì •ì˜\n","\n","code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n","            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n","\n","idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n","            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}\n","\n","# ì‹œí€€ìŠ¤ ë°ì´í„° ì •ì˜\n","\n","seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n","       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n","       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n","       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']\n","\n","# 2. ë°ì´í„°ì…‹ ìƒì„±í•˜ê¸°\n","\n","dataset = seq2dataset(seq, window_size = 4)\n","\n","print(dataset.shape)\n","\n","# ì…ë ¥(X)ê³¼ ì¶œë ¥(Y) ë³€ìˆ˜ë¡œ ë¶„ë¦¬í•˜ê¸°\n","x_train = dataset[:,0:4]\n","y_train = dataset[:,4]\n","\n","max_idx_value = 13\n","\n","# ì…ë ¥ê°’ ì •ê·œí™” ì‹œí‚¤ê¸°\n","x_train = x_train / float(max_idx_value)\n","\n","# ì…ë ¥ì„ (ìƒ˜í”Œ ìˆ˜, íƒ€ì„ìŠ¤í…, íŠ¹ì„± ìˆ˜)ë¡œ í˜•íƒœ ë³€í™˜\n","x_train = np.reshape(x_train, (50, 4, 1))\n","\n","# ë¼ë²¨ê°’ì— ëŒ€í•œ one-hot ì¸ì½”ë”© ìˆ˜í–‰\n","y_train = np_utils.to_categorical(y_train)\n","\n","one_hot_vec_size = y_train.shape[1]\n","\n","print(\"one hot encoding vector size is \", one_hot_vec_size)\n","\n","# 3. ëª¨ë¸ êµ¬ì„±í•˜ê¸°\n","model = Sequential()\n","model.add(LSTM(128, batch_input_shape = (1, 4, 1), stateful=True))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))\n","    \n","# 4. ëª¨ë¸ í•™ìŠµê³¼ì • ì„¤ì •í•˜ê¸°\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# 5. ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸°\n","num_epochs = 2000\n","\n","history = LossHistory() # ì†ì‹¤ ì´ë ¥ ê°ì²´ ìƒì„±\n","\n","history.init()\n","\n","for epoch_idx in range(num_epochs):\n","    print ('epochs : ' + str(epoch_idx) )\n","    model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2, shuffle=False, callbacks=[history]) # 50 is X.shape[0]\n","    model.reset_states()\n","    \n","# 6. í•™ìŠµê³¼ì • ì‚´í´ë³´ê¸°\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.plot(history.losses)\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train'], loc='upper left')\n","plt.show()\n","\n","# 7. ëª¨ë¸ í‰ê°€í•˜ê¸°\n","scores = model.evaluate(x_train, y_train, batch_size=1)\n","print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n","model.reset_states()\n","\n","# 8. ëª¨ë¸ ì‚¬ìš©í•˜ê¸°\n","\n","pred_count = 50 # ìµœëŒ€ ì˜ˆì¸¡ ê°œìˆ˜ ì •ì˜\n","\n","# í•œ ìŠ¤í… ì˜ˆì¸¡\n","\n","seq_out = ['g8', 'e8', 'e4', 'f8']\n","pred_out = model.predict(x_train, batch_size=1)\n","\n","for i in range(pred_count):\n","    idx = np.argmax(pred_out[i]) # one-hot ì¸ì½”ë”©ì„ ì¸ë±ìŠ¤ ê°’ìœ¼ë¡œ ë³€í™˜\n","    seq_out.append(idx2code[idx]) # seq_outëŠ” ìµœì¢… ì•…ë³´ì´ë¯€ë¡œ ì¸ë±ìŠ¤ ê°’ì„ ì½”ë“œë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥\n","\n","model.reset_states()\n","    \n","print(\"one step prediction : \", seq_out)\n","\n","# ê³¡ ì „ì²´ ì˜ˆì¸¡\n","\n","seq_in = ['g8', 'e8', 'e4', 'f8']\n","seq_out = seq_in\n","seq_in = [code2idx[it] / float(max_idx_value) for it in seq_in] # ì½”ë“œë¥¼ ì¸ë±ìŠ¤ê°’ìœ¼ë¡œ ë³€í™˜\n","\n","for i in range(pred_count):\n","    sample_in = np.array(seq_in)\n","    sample_in = np.reshape(sample_in, (1, 4, 1)) # ìƒ˜í”Œ ìˆ˜, íƒ€ì…ìŠ¤í… ìˆ˜, ì†ì„± ìˆ˜\n","    pred_out = model.predict(sample_in)\n","    idx = np.argmax(pred_out)\n","    seq_out.append(idx2code[idx])\n","    seq_in.append(idx / float(max_idx_value))\n","    seq_in.pop(0)\n","\n","model.reset_states()\n","    \n","print(\"full song prediction : \", seq_out)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hiy1P4VdCY7m"},"source":["í•œ ìŠ¤í… ì˜ˆì¸¡ ê²°ê³¼ì™€ ê³¡ ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì•…ë³´ë¡œ ê·¸ë ¤ë³´ì•˜ìŠµë‹ˆë‹¤. Stateful LSTMì€ ìŒí‘œë¥¼ ëª¨ë‘ ë§ì¶”ì–´ì„œ, ì „ì²´ ê³¡ ì˜ˆì¸¡ë„ ì •í™•í•˜ê²Œ í–ˆìŠµë‹ˆë‹¤.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_Stateful_LSTM_song.png)\n","\n","ìœ„ ì•…ë³´ë¡œ ì—°ì£¼í•œ ê³¡ì€ ì•„ë˜ ë§í¬ì—ì„œ ë‹¤ìš´ë¡œë“œ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","* [http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f1_one_step_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f1_one_step_prediction.mp3)\n","* [http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f1_full_song_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f1_full_song_prediction.mp3)"]},{"cell_type":"markdown","metadata":{"id":"2xvIG0TrCY7m"},"source":["### *ì…ë ¥ ì†ì„±ì´ ì—¬ëŸ¬ ê°œì¸ ëª¨ë¸ êµ¬ì„±*\n","\n","ì…ë ¥ ì†ì„±ì´ ì—¬ëŸ¬ ê°œì¸ ê²½ìš°ì— ëŒ€í•´ì„œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ 'ê¸°ì˜¨'ë¼ëŠ” ê²ƒì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ì„œ ì…ë ¥ìœ¼ë¡œ 'ê¸°ì˜¨'ë¿ë§Œì•„ë‹ˆë¼ 'ìŠµë„', 'ê¸°ì••', 'í’í–¥', 'í’ì†' ë“± ë‹¤ì–‘í•œ ì†ì„±ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒíƒœìœ ì§€ LSTM ëª¨ë¸ì—ì„œ ì…ë ¥í˜•íƒœë¥¼ batch_input_shape = (ë°°ì¹˜ì‚¬ì´ì¦ˆ, íƒ€ì„ìŠ¤í…, ì†ì„±)ìœ¼ë¡œ ì„¤ì •í•˜ëŠ”ë°, ë§ˆì§€ë§‰ ì¸ìë¥¼ í†µí•´ ì†ì„±ì˜ ê°œìˆ˜ë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'ë‚˜ë¹„ì•¼' ì˜ˆì œì—ì„œëŠ” í˜„ì¬ ì…ë ¥ê°’ì´ 'c4, e4, g8'ë“±ìœ¼ë¡œ ë˜ì–´ ìˆëŠ” ë°, ì´ë¥¼ ìŒì •ê³¼ ìŒê¸¸ì´ë¡œ ë‚˜ëˆ„ì–´ì„œ 2ê°œì˜ ì†ì„±ìœ¼ë¡œ ì…ë ¥í•´ë³´ê² ìŠµë‹ˆë‹¤. ì¦‰ 'c4'ëŠ” '(c, 4)'ë¡œ ë‚˜ëˆ„ì–´ì„œ ì…ë ¥í•˜ê²Œ ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ë°ì´í„°ì…‹ ë§Œë“œëŠ” í•¨ìˆ˜ë¥¼ ì•„ë˜ì™€ ê°™ì´ ìˆ˜ì •í•˜ì˜€ìŠµë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"jG3POYl9CY7m"},"source":["def code2features(code):\n","    features = []\n","    features.append(code2scale[code[0]]/float(max_scale_value))\n","    features.append(code2length[code[1]])\n","    return features"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UJeI8YJGCY7m"},"source":["LSTM ëª¨ë¸ ìƒì„± ì‹œ batch_input_shape ì¸ìì˜ ë§ˆì§€ë§‰ ê°’ì´ '1'ì—ì„œ '2'ë¡œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Fjg9H4dbCY7n"},"source":["model = Sequential()\n","model.add(LSTM(128, batch_input_shape = (1, 4, 2), stateful=True))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n3A0Jst0CY7n"},"source":["ì•„ë˜ ê·¸ë¦¼ì„ ë³´ì‹œë©´ ì…ë ¥ì´ ë‘ ê°œë¡œ ë‚˜ëˆ„ì–´ì§ì„ ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë°©ì‹ì€ 'c8'ì´ë‹ˆ 'd4'ì²˜ëŸ¼ ì½”ë“œ ìì²´ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ìŒì •ê³¼ ìŒê¸¸ì´ë¥¼ ë‚˜ëˆ„ì–´ì„œ í•™ìŠµí•˜ëŠ” íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ëŒì´ ì•…ë³´ë¥¼ ì½ì„ ë•Œë„ ì´ ë‘˜ì€ ë‚˜ëˆ„ì–´ì„œ ì¸ì§€ë¥¼ í•˜ë‹ˆ ì¢€ ë” ì‚¬ëŒì— ê°€ê¹Œìš´ í•™ìŠµì´ë¼ê³  ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_train_stateful_LSTM_features.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TGa-foECdLYA"},"source":["#### ì†ŒìŠ¤ì½”ë“œ\n","\n","ì „ì²´ ì†ŒìŠ¤ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."]},{"cell_type":"code","metadata":{"id":"IoX5sMJcCY7n"},"source":["# 0. ì‚¬ìš©í•  íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n","import keras\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM\n","from keras.utils import np_utils\n","\n","# ëœë¤ì‹œë“œ ê³ ì •ì‹œí‚¤ê¸°\n","np.random.seed(5)\n","\n","# ì†ì‹¤ ì´ë ¥ í´ë˜ìŠ¤ ì •ì˜\n","class LossHistory(keras.callbacks.Callback):\n","    def init(self):\n","        self.losses = []\n","        \n","    def on_epoch_end(self, batch, logs={}):\n","        self.losses.append(logs.get('loss'))\n","\n","# ë°ì´í„°ì…‹ ìƒì„± í•¨ìˆ˜\n","def seq2dataset(seq, window_size):\n","    dataset_X = []\n","    dataset_Y = []\n","    \n","    for i in range(len(seq)-window_size):\n","        \n","        subset = seq[i:(i+window_size+1)]\n","        \n","        for si in range(len(subset)-1):\n","            features = code2features(subset[si])            \n","            dataset_X.append(features)\n","\n","        dataset_Y.append([code2idx[subset[window_size]]])\n","        \n","    return np.array(dataset_X), np.array(dataset_Y)\n","\n","# ì†ì„± ë³€í™˜ í•¨ìˆ˜\n","def code2features(code):\n","    features = []\n","    features.append(code2scale[code[0]]/float(max_scale_value))\n","    features.append(code2length[code[1]])\n","    return features\n","\n","# 1. ë°ì´í„° ì¤€ë¹„í•˜ê¸°\n","\n","# ì½”ë“œ ì‚¬ì „ ì •ì˜\n","\n","code2scale = {'c':0, 'd':1, 'e':2, 'f':3, 'g':4, 'a':5, 'b':6}\n","code2length = {'4':0, '8':1}\n","\n","code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n","            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n","\n","idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n","            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}\n","\n","max_scale_value = 6.0\n","    \n","# ì‹œí€€ìŠ¤ ë°ì´í„° ì •ì˜\n","seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n","       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n","       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n","       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']\n","\n","# 2. ë°ì´í„°ì…‹ ìƒì„±í•˜ê¸°\n","\n","x_train, y_train = seq2dataset(seq, window_size = 4)\n","\n","# ì…ë ¥ì„ (ìƒ˜í”Œ ìˆ˜, íƒ€ì„ìŠ¤í…, íŠ¹ì„± ìˆ˜)ë¡œ í˜•íƒœ ë³€í™˜\n","x_train = np.reshape(x_train, (50, 4, 2))\n","\n","# ë¼ë²¨ê°’ì— ëŒ€í•œ one-hot ì¸ì½”ë”© ìˆ˜í–‰\n","y_train = np_utils.to_categorical(y_train)\n","\n","one_hot_vec_size = y_train.shape[1]\n","\n","print(\"one hot encoding vector size is \", one_hot_vec_size)\n","\n","# 3. ëª¨ë¸ êµ¬ì„±í•˜ê¸°\n","model = Sequential()\n","model.add(LSTM(128, batch_input_shape = (1, 4, 2), stateful=True))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))\n","    \n","# 4. ëª¨ë¸ í•™ìŠµê³¼ì • ì„¤ì •í•˜ê¸°\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# 5. ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸°\n","num_epochs = 2000\n","\n","history = LossHistory() # ì†ì‹¤ ì´ë ¥ ê°ì²´ ìƒì„±\n","history.init()\n","\n","for epoch_idx in range(num_epochs):\n","    print ('epochs : ' + str(epoch_idx) )\n","    model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2, shuffle=False, callbacks=[history]) # 50 is X.shape[0]\n","    model.reset_states()\n","    \n","# 6. í•™ìŠµê³¼ì • ì‚´í´ë³´ê¸°\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.plot(history.losses)\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train'], loc='upper left')\n","plt.show()\n","\n","# 7. ëª¨ë¸ í‰ê°€í•˜ê¸°\n","scores = model.evaluate(x_train, y_train, batch_size=1)\n","print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n","model.reset_states()\n","\n","# 8. ëª¨ë¸ ì‚¬ìš©í•˜ê¸°\n","\n","pred_count = 50 # ìµœëŒ€ ì˜ˆì¸¡ ê°œìˆ˜ ì •ì˜\n","\n","# í•œ ìŠ¤í… ì˜ˆì¸¡\n","\n","seq_out = ['g8', 'e8', 'e4', 'f8']\n","pred_out = model.predict(x_train, batch_size=1)\n","\n","for i in range(pred_count):\n","    idx = np.argmax(pred_out[i]) # one-hot ì¸ì½”ë”©ì„ ì¸ë±ìŠ¤ ê°’ìœ¼ë¡œ ë³€í™˜\n","    seq_out.append(idx2code[idx]) # seq_outëŠ” ìµœì¢… ì•…ë³´ì´ë¯€ë¡œ ì¸ë±ìŠ¤ ê°’ì„ ì½”ë“œë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥\n","    \n","print(\"one step prediction : \", seq_out)\n","\n","model.reset_states()\n","\n","# ê³¡ ì „ì²´ ì˜ˆì¸¡\n","\n","seq_in = ['g8', 'e8', 'e4', 'f8']\n","seq_out = seq_in\n","\n","seq_in_featrues = []\n","\n","for si in seq_in:\n","    features = code2features(si)\n","    seq_in_featrues.append(features)\n","\n","for i in range(pred_count):\n","    sample_in = np.array(seq_in_featrues)\n","    sample_in = np.reshape(sample_in, (1, 4, 2)) # ìƒ˜í”Œ ìˆ˜, íƒ€ì…ìŠ¤í… ìˆ˜, ì†ì„± ìˆ˜\n","    pred_out = model.predict(sample_in)\n","    idx = np.argmax(pred_out)\n","    seq_out.append(idx2code[idx])\n","    \n","    features = code2features(idx2code[idx])\n","    seq_in_featrues.append(features)\n","    seq_in_featrues.pop(0)\n","\n","model.reset_states()\n","    \n","print(\"full song prediction : \", seq_out)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j-HqOvKNCY7o"},"source":["ìˆ˜í–‰ê²°ê³¼ëŠ” ê³¡ ì „ì²´ë¥¼ ì •í™•í•˜ê²Œ ì˜ˆì¸¡ì„ í–ˆìŠµë‹ˆë‹¤.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_Stateful_LSTM_features_song.png)\n","\n","ìœ„ ì•…ë³´ë¡œ ì—°ì£¼í•œ ê³¡ì€ ì•„ë˜ ë§í¬ì—ì„œ ë‹¤ìš´ë¡œë“œ ë°›ìœ¼ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","* [http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f2_one_step_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f2_one_step_prediction.mp3)\n","* [http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f2_full_song_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f2_full_song_prediction.mp3)"]},{"cell_type":"markdown","metadata":{"id":"wtEzRcZNCY7o"},"source":["---\n","\n","### ìš”ì•½\n","\n","ìµìˆ™í•œ ë…¸ë˜ì¸ \"ë‚˜ë¹„ì•¼\"ë¥¼ ê°€ì§€ê³  ìˆœí•œ ì‹ ê²½ë§ ëª¨ë¸ì— í•™ìŠµì‹œì¼œë´¤ìŠµë‹ˆë‹¤. ìˆœí•­ ì‹ ê²½ë§ ëª¨ë¸ ì¤‘ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” LSTM ëª¨ë¸ì— ëŒ€í•´ì„œ ì•Œì•„ë³´ê³ , ì£¼ìš” ì¸ìë“¤ì´ ì–´ë–¤ íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆëŠ” ì§€ë„ ì‚´í´ë³´ì•˜ìŠµë‹ˆë‹¤. ì•ì„œ ì‚´í´ë³¸ 4ê°€ì§€ ëª¨ë¸ì— ëŒ€í•´ì„œ í•™ìŠµ ì†ì‹¤ê°’ì„ ê·¸ë˜í”„ë¡œ í‘œì‹œí•´ë´¤ìŠµë‹ˆë‹¤. ë‹¤ì¸µí¼ì…‰íŠ¸ë¡  ëª¨ë¸ > ê¸°ë³¸ LSTM ëª¨ë¸ > ìƒíƒœìœ ì§€ LSTM ëª¨ë¸ (1ê°œ ì†ì„±) > ìƒíƒœìœ ì§€ LSTM ëª¨ë¸ (2ê°œ ì†ì„±) ìˆœìœ¼ë¡œ ë” ë¹¨ë¦¬ í•™ìŠµë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_loss_history.png)"]},{"cell_type":"code","metadata":{"id":"ssWFM2i0CuH4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E-Slhf2tq6ar"},"source":["## **Lab 2**"]},{"cell_type":"markdown","metadata":{"id":"ItLEd6uBq993"},"source":["ë‹¤ë¥¸ ë…¸ë˜ë¥¼ ì´ìš©í•´ì„œ, 3ì¥ì—ì„œì™€ ê°™ì€ ë°©ì‹ìœ¼ë¡œ <u>ì•…ë³´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸</u>ì„ í•™ìŠµí•˜ê³ , ì¶œë ¥ ê²°ê³¼ë¡œë¶€í„° ì„±ëŠ¥ì„ í™•ì¸í•©ë‹ˆë‹¤.\n","\n","*   ìˆœí™˜ ì‹ ê²½ë§ ëª¨ë¸ì˜ ë ˆì´ì–´ ë˜ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ììœ ë¡­ê²Œ ì¡°ì ˆ\n","*   ë˜ëŠ”, ì‚¬ì „ ë°ì´í„°ë¥¼ ì°¸ì¡°í•˜ëŠ” ìœˆë„ìš° ë²”ìœ„<small>(e.g., ì˜ˆì œì—ì„œ 20ê°œ ë³´ê³  ì˜ˆì¸¡)</small> ë“±ì„ ììœ ë¡­ê²Œ ì¡°ì ˆ\n","\n","ì‹¤ìŠµì½”ë“œì˜ ê²°ê³¼ë¥¼ ì´ˆê³¼í•˜ì—¬ ì„±ëŠ¥ì´ í–¥ìƒë˜ëŠ” êµ¬ì„±ì„ ë§Œë“¤ì–´ë³´ê³ , ì¶œë ¥ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n","\n","**â€» ì œì¶œë°©ë²•:** ì‹¤ìŠµë‚´ìš© ë° ì¶œë ¥ ê²°ê³¼ê°€ ì €ì¥ëœ Colab íŒŒì¼(`*.ipynb`)ë¥¼ KLMSì˜ ê³¼ì œ í•­ëª©ì— ì—…ë¡œë“œ"]},{"cell_type":"markdown","metadata":{"id":"vhCTUS0trvK0"},"source":["### **<small>(ì°¸ê³ )</small> ì•…ë³´ ì‹œê°í™” íˆ´ ì„¤ì¹˜**\n","\n","*   Abjad ê³µì‹ í™ˆí˜ì´ì§€: https://abjad.github.io/\n","  - Documantation:  http://abjad.mbrsi.org/index.html\n","*   LilyPond ê³µì‹ í™ˆí˜ì´ì§€: http://lilypond.org/development.html\n"]},{"cell_type":"markdown","metadata":{"id":"Ziwx8ztxsMav"},"source":["#### *Abjad íŒŒì´ì¬ ëª¨ë“ˆ ì„¤ì¹˜*\n"]},{"cell_type":"code","metadata":{"id":"6tMj66Ubedap"},"source":["!pip install abjad[development,ipython]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r6FCOWV4sO3u"},"source":["#### *LilyPond ë¦¬ëˆ…ìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜*\n"]},{"cell_type":"code","metadata":{"id":"A5Io9ckZfkAE"},"source":["# ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´ë¡œë“œ\n","!wget https://lilypond.org/download/binaries/linux-64/lilypond-2.22.0-1.linux-64.sh"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"30x1o0AffxJ1"},"source":["# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ í›„, ì¶œë ¥ ì½˜ì†”ì—ì„œ Enter ì…ë ¥í•˜ì—¬ ì„¤ì¹˜ ì§„í–‰\n","!sh lilypond-2.22.0-1.linux-64.sh"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CEvgUenniCft"},"source":["# ì •ìƒ ì„¤ì¹˜ì—¬ë¶€ í™•ì¸\n","!lilypond --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JIob8LGJjAj5"},"source":["# ìœ„ ë²„ì „ í™•ì¸ ë‹¨ê³„ì—ì„œ, \n","#   íŠ¹ì • ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ë‹¤ê³  í•˜ëŠ” ê²½ìš°, ë¬¸ì œí•´ê²°ì„ ìœ„í•´ ì‹¬ë³¼ë¦­ ë§í¬ ì¬ìƒì„±\n","!rm /usr/local/lilypond/usr/lib/libstdc++.so.6 \n","!ln -s /usr/lib/x86_64-linux-gnu/libstdc++.so.6 /usr/local/lilypond/usr/lib/libstdc++.so.6 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ui4WCr7Ysx81"},"source":["#### *ì•…ë³´ì¶œë ¥ ê¸°ëŠ¥ í™•ì¸*\n"]},{"cell_type":"code","metadata":{"id":"ih3KzZVypmIs"},"source":["%load_ext abjadext.ipython"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gwpwK4C3eZGu"},"source":["import abjad\n","seq = \"c'16 f' g' a' d' g' a' b' e' a' b' c'' f' b' c'' d''16\"\n","voice_1 = abjad.Voice(seq, name=\"Voice_1\")\n","staff_1 = abjad.Staff([voice_1], name=\"Staff_1\")\n","abjad.show(staff_1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cDt09hNjtEEp"},"source":["### **ì‹ ê·œ ì•…ë³´ ë° ì½”ë“œ ì‘ì„±ì˜ì—­**\n"]},{"cell_type":"markdown","metadata":{"id":"dSLHaQsiwrGp"},"source":["#### *ì‹ ê·œ ì•…ë³´: ë¹„í–‰ê¸° (ë™ìš”)*"]},{"cell_type":"code","metadata":{"id":"uzbRwfthte3k"},"source":["seq_lab2 = \"e'8. d'16 c'8 d'8 e'8 e'8 e'4\"\\\n","            + \" d'8 d'8 d' e'8 e'8 e'\"\\\n","            + \" e'8. d'16 c'8 d'8 e'8 e'8 e'\"\\\n","            + \" d'8 d'8 e'8. d'16 c'1\"\n","\n","voice_1 = abjad.Voice(seq_lab2, name=\"Voice_1\")\n","staff_1 = abjad.Staff([voice_1], name=\"Staff_1\")\n","abjad.show(staff_1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"47Hdg5Caw2AT"},"source":["#### *ì½”ë“œ ì‘ì„±ì˜ì—­*\n"]},{"cell_type":"code","metadata":{"id":"jVYEYS15wpi6"},"source":["######\n","## 3ì¥ ë‚´ìš©ì„ ì°¸ì¡°í•´ì„œ Lab2ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n","######\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]}]}