{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2103258_prac03.ipynb","provenance":[{"file_id":"1kX6E7TYXik-jG4b6G7DL_DIk3nbP3U1B","timestamp":1616034118537}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyN6O4k8GCDopxhn7RLcU6Z0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"i33z4PFj7SPF"},"source":["\\[SEP592\\] 소프트웨어 특강 <데이터사이언스 입문>\n","# 4주차 실습 파트\n","\n","> 강의일: 2021.03.25.\n","\n","👤 실습담당자: 임채균 (KAIST 전산학부) &nbsp;&nbsp; | &nbsp;&nbsp; 📧 Email: rayote@kaist.ac.kr\n","\n","---\n","<br />\n","\n","#### &nbsp;&nbsp; *실습 목표*\n","\n","*   사전학습된 VGG 모델을 Keras에서 사용하는 방법을 확인함.\n","*   Keras 환경에서 <u>RNN (Recurrent Neural Network)의 구조 및 사용법</u>을 학습함.\n","\n","\n","\n","<br />\n","\n","#### &nbsp;&nbsp; *References*\n","\n","*   김태영, “블록과 함께 하는 파이썬 딥러닝 케라스,” 디지털\n","북스, 2017.\n","  * 김태영의 케라스 블로그 <small>https://tykimos.github.io/lecture/</small>\n","\n","<br />\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"arW3XP-uLgkx"},"source":["##### *(참고)* 각각의 코드 셀의 실행시간을 자동으로 측정해주는 모듈을 설치함."]},{"cell_type":"code","metadata":{"id":"QKkgeDyuLktL"},"source":["# 각 코드 셀의 실행시간 측정 모듈\n","!pip install ipython-autotime\n","\n","%load_ext autotime"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uzrYGRK2ixFg"},"source":["##### Keras 버전 차이로 실습 시 에러 발생하므로, 구버전으로 재설치\n","\n","*   재설치 버전 \n","    - keras 2.3.1\n","    -   tensorflow 2.2.0 "]},{"cell_type":"code","metadata":{"id":"DAzsOyiziwxB"},"source":["# 기존 keras 삭제하기\n","!pip uninstall -y keras\n","!pip uninstall -y tensorflow\n","\n","# 구버전 재설치\n","!pip install keras==2.3.1\n","!pip install tensorflow==2.2.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NZByadnfjafF"},"source":["import keras\n","print(keras.__version__)\n","\n","import tensorflow as tf\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eVRPshpP4Nhq"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sH--H1yJOPXv"},"source":["## **<small>(지난 실습 cont'd)</small> 5. 사전학습된 VGG 모델 사용**"]},{"cell_type":"markdown","metadata":{"id":"SmM7bAS6O6tX"},"source":["### **도전 시험셋 데이터 준비**"]},{"cell_type":"code","metadata":{"id":"zGxfL1OiO5ax"},"source":["# Colab 환경에 데이터 받기\n","!wget https://github.com/tykimos/tykimos.github.io/raw/master/warehouse/2017-3-8-CNN_Data_Augmentation_hard_handwriting_shape.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TMp-43YnO5a0"},"source":["# 데이터 경로(warehouse/)에 압축 해제하기\n","!unzip 2017-3-8-CNN_Data_Augmentation_hard_handwriting_shape.zip -d warehouse"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"smyStQBQRpaw"},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","# 랜덤시드 고정시키기\n","np.random.seed(3)\n","\n","# 데이터 생성하기\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","        'warehouse/hard_handwriting_shape/train',\n","        target_size=(224, 224),   # VGG는 이미지를 224×224 크기 사용\n","        batch_size=3,\n","        class_mode='categorical')\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","test_generator = test_datagen.flow_from_directory(\n","        'warehouse/hard_handwriting_shape/test',\n","        target_size=(224, 224),   # VGG는 이미지를 224×224 크기 사용\n","        batch_size=3,\n","        class_mode='categorical')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ToB1sCtdOPXw"},"source":["### **VGG-16 모델**\n","\n","*참조 레퍼런스*\n","\n","https://machinelearningmastery.com/use-pre-trained-vgg-model-classify-objects-photographs/\n","\n","<br />\n","\n","**주요 파라미터**\n","\n","*   `include_top (True)`: \n","  - Whether or not to include the output layers for the model. You don’t need these if you are fitting the model on your own problem.\n","*   `weights ('imagenet')`: \n","  - What weights to load. You can specify None to not load pre-trained weights if you are interested in training the model yourself from scratch.\n","*   `input_tensor (None)`: \n","  - A new input layer if you intend to fit the model on new data of a different size.\n","*   `input_shape (None)`: \n","  - The size of images that the model is expected to take if you change the input layer.\n","*   `pooling (None)`: \n","  - The type of pooling to use when you are training a new set of output layers.\n","*   `classes (1000)`: \n","  - The number of classes (e.g. size of output vector) for the model."]},{"cell_type":"code","metadata":{"id":"GLW6XGNvOPXy"},"source":["from keras.applications.vgg16 import VGG16\n","model = VGG16()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Lrc6RAgOPXz"},"source":["from IPython.display import SVG\n","from keras.utils.vis_utils import model_to_dot\n","\n","%matplotlib inline\n","\n","SVG(model_to_dot(model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c-fH0exVOPXz"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5l7pvxzDOPX0"},"source":["##### *입력 이미지 데이터 준비*"]},{"cell_type":"markdown","metadata":{"id":"2n-43mHPOPX0"},"source":["VGG 모델에서는 입력 이미지를 224×224 크기로 사용합니다."]},{"cell_type":"code","metadata":{"id":"8yl9yoJdOPX1"},"source":["from keras.preprocessing.image import load_img\n","# load an image from file\n","path_img = 'warehouse/hard_handwriting_shape/train/triangle/triangle001.png'\n","image = load_img(path_img, target_size=(224, 224))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PGTuU0JXOPX2"},"source":["`Numpy` 배열로 변경하고, 기존 VGG 모델에 맞도록 추가 dimension을 포함하도록 `reshape()` 합니다."]},{"cell_type":"code","metadata":{"id":"TPXUdbHqOPX2"},"source":["from keras.preprocessing.image import img_to_array\n","# convert the image pixels to a numpy array\n","image = img_to_array(image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kV1RurawOPX2"},"source":["# reshape data for the model\n","image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FZtpMc4MOPX2"},"source":["Keras에서 제공하는 VGG모델의 입력 전처리 함수 `preprocess_input()`을 적용합니다."]},{"cell_type":"code","metadata":{"id":"IWDo05EaOPX3"},"source":["from keras.applications.vgg16 import preprocess_input\n","# prepare the image for the VGG model\n","image = preprocess_input(image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CWr0alTAOPX3"},"source":["##### *모델을 사용하여 예측 실행*"]},{"cell_type":"code","metadata":{"id":"44-P-Ug-OPX3"},"source":["# predict the probability across all output classes\n","yhat = model.predict(image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WZYEOT6FOPX3"},"source":["##### *예측결과 해석*"]},{"cell_type":"code","metadata":{"id":"Ozwa-GZ9OPX3"},"source":["from keras.applications.vgg16 import decode_predictions\n","# convert the probabilities to class labels\n","label = decode_predictions(yhat)\n","# retrieve the most likely result, e.g. highest probability\n","label = label[0][0]\n","# print the classification\n","print('%s (%.2f%%)' % (label[1], label[2]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4_oekJQOPX3"},"source":["import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","plt.imshow(image.reshape(224, 224, 3))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RUxIfJxpOPX4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tYSK9RBxOPX4"},"source":["#### *전체 코드 재정리 (함수화)*"]},{"cell_type":"code","metadata":{"id":"VRZbiUsIOPX4"},"source":["from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.vgg16 import preprocess_input\n","\n","# 입력 전처리 함수\n","def preproc_image_vgg(path_img):\n","  # load an image from file\n","  image = load_img(path_img, target_size=(224, 224))\n","\n","  # convert the image pixels to a numpy array\n","  image = img_to_array(image)\n","\n","  # reshape data for the model\n","  image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","\n","  # prepare the image for the VGG model\n","  image = preprocess_input(image)\n","\n","  return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NemXwwi7OPX4"},"source":["from keras.applications.vgg16 import decode_predictions\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# 결과 해석 및 출력 함수\n","def print_result_vgg(yhat, image):\n","  # convert the probabilities to class labels\n","  label = decode_predictions(yhat)\n","  # retrieve the most likely result, e.g. highest probability\n","  label = label[0][0]\n","  # print the classification\n","  print('> Predicted Label=  %s (%.2f%%)' % (label[1], label[2]*100))\n","\n","  # show an image\n","  plt.imshow(image.reshape(224, 224, 3))\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wd5lJfJ9OPX4"},"source":["# VGG를 활용한 전체 예측과정 함수\n","def predict_vgg(path_img):\n","  image = preproc_image_vgg(path_img)\n","\n","  # predict the probability across all output classes\n","  yhat = model.predict(image)\n","\n","  print_result_vgg(yhat, image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"awOmgxpJOPX5"},"source":["##### *실행결과 테스트*"]},{"cell_type":"code","metadata":{"id":"dz_EtDm5OPX5"},"source":["predict_vgg('warehouse/hard_handwriting_shape/train/triangle/triangle001.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c4vpMOKMOPX5"},"source":["predict_vgg('warehouse/hard_handwriting_shape/train/circle/circle001.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2U_CH2DROPX5"},"source":["predict_vgg('warehouse/hard_handwriting_shape/train/rectangle/rectangle001.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZnBN2PnHOoVG"},"source":["### **VGG-16 모델에 대한 Fine-tuning**"]},{"cell_type":"markdown","metadata":{"id":"0EESrCEmPNB0"},"source":["#### *모델 추가 구성하기 (1) - 예측 레이어 추가*"]},{"cell_type":"code","metadata":{"id":"6QSlqL77OPX5"},"source":["from keras.layers import Dense, GlobalAveragePooling1D\n","from keras import Model\n","\n","base_model = VGG16()\n","\n","# let's add a fully-connected layer\n","x = base_model.output\n","x = Dense(256, activation='relu')(x)\n","\n","# and a logistic layer -- let's say we have 3 classes\n","predictions = Dense(3, activation='softmax')(x)\n","\n","# this is the model we will train\n","model = Model(inputs=base_model.input, outputs=predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_-5DK7B04NfK"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"op4QSVsl4Nca"},"source":["# first: train only the top layers (which were randomly initialized)\n","# i.e. freeze all convolutional layers\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# compile the model (should be done *after* setting layers to non-trainable)\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q31CqSVbOOPZ"},"source":["# 모델 학습시키기\n","model.fit_generator(\n","        train_generator,\n","        steps_per_epoch=15,\n","        epochs=10,\n","        validation_data=test_generator,\n","        validation_steps=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HtW6eIG2Z7oV"},"source":["# 모델 평가하기\n","print(\"-- Evaluate --\")\n","scores = model2.evaluate_generator(test_generator, steps=15)\n","print(\"%s: %.2f%%\" %(model2.metrics_names[1], scores[1]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YAyNolVjWt0A"},"source":["#### *모델 추가 구성하기 (2) - 사전모델 일부 레이어 활용*"]},{"cell_type":"code","metadata":{"id":"uCUK1NI3OOKQ"},"source":["base_model2 = VGG16()\n","\n","# let's add a fully-connected layer\n","x = base_model2.output\n","x = Dense(64, activation='relu')(x)\n","\n","# and a logistic layer -- let's say we have 3 classes\n","predictions = Dense(3, activation='softmax')(x)\n","\n","# this is the model we will train\n","model2 = Model(inputs=base_model2.input, outputs=predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o4_4437oXNur"},"source":["# we chose to train the top 2 inception blocks, i.e. we will freeze\n","# other layers\n","for layer in base_model2.layers[:-2]:\n","    layer.trainable = False\n","for layer in base_model2.layers[-2:]:\n","    layer.trainable = True\n","\n","# compile the model (should be done *after* setting layers to non-trainable)\n","model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ivUAAY6rXlj8"},"source":["# 모델 학습시키기\n","model2.fit_generator(\n","        train_generator,\n","        steps_per_epoch=15,\n","        epochs=10,\n","        validation_data=test_generator,\n","        validation_steps=5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QblwyY1ZZ47A"},"source":["# 모델 평가하기\n","print(\"-- Evaluate --\")\n","scores = model2.evaluate_generator(test_generator, steps=15)\n","print(\"%s: %.2f%%\" %(model2.metrics_names[1], scores[1]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g9Duge9tYEJv"},"source":["---\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"TPzu-4Td5jJu"},"source":["## **1. LSTM 모델의 기본 개념**\n"]},{"cell_type":"markdown","metadata":{"id":"4UX7AJp45L-7"},"source":["순환 신경망 모델은 순차적인 자료에서 규칙적인 패턴을 인식하거나 그 의미를 추론할 수 있습니다. 순차적이라는 특성 때문에 간단한 레이어로도 다양한 형태의 모델을 구성할 수 있습니다. 케라스에서 제공하는 순환 신경망 레이어는 SimpleRNN, GRU, LSTM이 있으나 주로 사용하는 LSTM에 대해서 알아보겠습니다. "]},{"cell_type":"markdown","metadata":{"id":"90kjNrIr5L-8"},"source":["---\n","\n","### **긴 시퀀스를 기억할 수 있는 LSTM (Long Short-Term Memory units)  레이어**\n","\n","LSTM 레이어는 아래와 같이 간단히 사용할 수 있습니다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Fkk14wvl5zKM"},"source":["#### *입력 형태*\n","\n","    LSTM(3, input_dim=1)\n","\n","기본 인자는 다음과 같습니다.\n","* 첫번째 인자 : 메모리 셀의 개수입니다.\n","* input_dim : 입력 속성 수 입니다.\n","\n","이는 앞서 살펴본 Dense 레이어 형태와 비슷합니다. 첫번째 인자인 메모리 셀의 개수는 기억용량 정도와 출력 형태를 결정짓습니다. Dense 레이어에서의 출력 뉴런 수와 비슷하다고 보시면 됩니다. input_dim에는 Dense 레이어와 같이 일반적으로 속성의 개수가 들어갑니다. \n","\n","    Dense(3, input_dim=1)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Y7ctneAB52hd"},"source":["LSTM의 한 가지 인자에 대해 더 알아보겠습니다.\n","\n","    LSTM(3, input_dim=1, input_length=4)\n","\n","* input_length : 시퀀스 데이터의 입력 길이\n","\n","Dense와 LSTM을 블록으로 도식화 하면 다음과 같습니다. 왼쪽이 Dense이고, 중앙이 input_length가 1인 LSTM이고 오른쪽이 input_length가 4인 LSTM 입니다. 사실 LSTM의 내부구조는 복잡하지만 간소화하여 외형만 표시한 것입니다. Dense 레이어와 비교한다면 히든 뉴런들이 밖으로 도출되어 있음을 보실 수 있습니다. 그리고 오른쪽 블록인 경우 input_length가 길다고 해서 각 입력마다 다른 가중치를 사용하는 것이 아니라 중앙에 있는 블록을 입력 길이 만큼 연결한 것이기 때문에 모두 동일한 가중치를 공유합니다.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_LSTM1.png)"]},{"cell_type":"markdown","metadata":{"id":"99sP_IRG5L-9"},"source":["#### *출력 형태*\n","\n","* return_sequences : 시퀀스 출력 여부\n","\n","LSTM 레이어는 return_sequences 인자에 따라 마지막 시퀀스에서 한 번만 출력할 수 있고 각 시퀀스에서 출력을 할 수 있습니다. many to many 문제를 풀거나 LSTM 레이어를 여러개로 쌓아올릴 때는 return_sequence=True 옵션을 사용합니다. 자세한 것은 뒤에서 살펴보겠습니다. 아래 그림에서 왼쪽은 return_sequences=False일 때, 오른쪽은 return_sequence=True일 때의 형상입니다.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_LSTM2.png)"]},{"cell_type":"markdown","metadata":{"id":"yXV6iIAk5L-9"},"source":["#### *상태유지(stateful) 모드*\n","\n","* stateful : 상태 유지 여부\n","\n","학습 샘플의 가장 마지막 상태가 다음 샘플 학습 시에 입력으로 전달 여부를 지정하는 것입니다. 하나의 샘플은 4개의 시퀀스 입력이 있고, 총 3개의 샘플이 있을 때, 아래 그림에서 위의 블록들은 stateful=False일 때의 형상이고, 아래 블록들은 stateful=True일 때의 형상입니다. 도출된 현재 상태의 가중치가 다음 샘플 학습 시의 초기 상태로 입력됨을 알 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"58slSSad5L--"},"source":["![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_LSTM3.png)"]},{"cell_type":"markdown","metadata":{"id":"8fEo9Fzj5L--"},"source":["---\n","\n","### 요약\n","\n","순환 신경망 레이어 중 LSTM 레이어에 대해서 알아봤습니다. 사용법은 Dense 레이어와 비슷하지만 시퀀스 출력 여부와 상태유지 모드 설정으로 다양한 형태의 신경망을 구성할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"u1-lXkpD6hR-"},"source":["## **2. LSTM 모델 시작하기**\n"]},{"cell_type":"markdown","metadata":{"id":"CGrPESdk6DpL"},"source":["본 강좌에서는 간단한 순환 신경망 모델을 만들어봅니다. 늘 그렇듯이 다음과 같은 순서로 진행하겠습니다.\n","\n","1. 문제 정의하기\n","1. 데이터셋 준비하기\n","1. 모델 구성하기\n","1. 모델 엮기\n","1. 모델 학습시키기\n","1. 모델 사용하기"]},{"cell_type":"markdown","metadata":{"id":"f7SMvf8A7jQ8"},"source":["### *모듈 임포트*"]},{"cell_type":"code","metadata":{"id":"TRsLnl_W6DpL"},"source":["import matplotlib.pyplot"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cagrMse06DpM"},"source":["import numpy as np\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Dropout\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import matplotlib.pyplot as plt\n","\n","import theano\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sG9uEdX76DpN"},"source":["### *데이터 생성*"]},{"cell_type":"code","metadata":{"id":"6Qde4RIx6DpN"},"source":["dataset = np.cos(np.arange(1000)*(20*np.pi/1000))[:,None]\n","\n","plt.plot(dataset)\n","\n","dataset.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"gbnOHLnl6DpN"},"source":["# convert an array of values into a dataset matrix\n","def create_dataset(dataset, look_back=1):\n","    dataX, dataY = [], []\n","    for i in range(len(dataset)-look_back):\n","        dataX.append(dataset[i:(i+look_back), 0])\n","        dataY.append(dataset[i + look_back, 0])\n","    return np.array(dataX), np.array(dataY)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OEfy83UZ6DpO"},"source":["### *학습/테스트 데이터 준비 (Window of 20 time steps)*"]},{"cell_type":"markdown","metadata":{"id":"1BeNCecKJCjh"},"source":["`look_back`에 지정된 `20`개 만큼의 이전 값을 보고, 그 다음 `1`개를 예측하기 위함."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"vK752u966DpO"},"source":["look_back = 20\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","dataset = scaler.fit_transform(dataset)\n","\n","# split into train and test sets\n","train_size = int(len(dataset) * 0.67)\n","test_size = len(dataset) - train_size\n","train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n","\n","trainX, trainY = create_dataset(train, look_back)\n","testX, testY = create_dataset(test, look_back)\n","\n","trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n","testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qf9JSC6pJW6L"},"source":["`train`에 포함된 데이터 전체 개수는 `670`개"]},{"cell_type":"code","metadata":{"id":"Qi9x-URU6DpO"},"source":["print(train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O8D4zW2MJddu"},"source":["그 중에서, 학습데이터 `trainX`는 길이 `20`개 단위로 구성되어, 총 `650`개"]},{"cell_type":"code","metadata":{"id":"cq05DSyd6DpP"},"source":["print(trainX.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bv_LADs2J0FZ"},"source":["`trainY`의 경우에도 쌍을 이루어 구성되므로, 총 `650`개"]},{"cell_type":"code","metadata":{"id":"1wIc12356DpP"},"source":["print(trainY.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sG65IJQ6J_pc"},"source":["### *간단한 LSTM 모델 학습*\n"]},{"cell_type":"code","metadata":{"id":"hTz4_avr6DpQ"},"source":["# create and fit the LSTM network\n","batch_size = 1\n","model = Sequential()\n","model.add(LSTM(32,input_dim=1))\n","model.add(Dropout(0.3))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adam')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"V9-mGxWc6DpQ"},"source":["model.fit(trainX, trainY, nb_epoch=10, batch_size=batch_size, verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4byOxpPQ6DpQ"},"source":["trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n","print('Train Score: ', trainScore)\n","testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n","print('Test Score: ', testScore)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IeT7NQk06DpQ"},"source":["print(trainX[-1][1:].shape)\n","print()\n","print(trainX[-1][1:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"8mXWcU_J6DpR"},"source":["look_ahead = 250\n","trainPredict = [np.vstack([trainX[-1][1:], trainY[-1]])]\n","predictions = np.zeros((look_ahead,1))\n","for i in range(look_ahead):\n","    predict = model.predict(np.array([trainPredict[-1]]), batch_size=batch_size)\n","    predictions[i] = predict\n","    trainPredict.append(np.vstack([trainPredict[-1][1:], predict]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B4HF1Scn6DpR"},"source":["plt.figure(figsize=(12,5))\n","# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n","plt.plot(np.arange(look_ahead), predictions,'r-.', label=\"prediction\")\n","plt.plot(np.arange(look_ahead), dataset[train_size:(train_size+look_ahead)], label=\"test function\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EgpGImtp6DpR"},"source":["### *Stateful LSTMs*"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"KFTqQCJ36DpR"},"source":["look_back = 20\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","dataset = scaler.fit_transform(dataset)\n","\n","# split into train and test sets\n","train_size = int(len(dataset) * 0.67)\n","test_size = len(dataset) - train_size\n","train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n","\n","trainX, trainY = create_dataset(train, look_back)\n","testX, testY = create_dataset(test, look_back)\n","\n","trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n","testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pT5PbAm_6DpR"},"source":["# create and fit the LSTM network\n","batch_size = 1\n","model = Sequential()\n","# model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n","# model.add(Dropout(0.3))\n","# model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n","# model.add(Dropout(0.3))\n","model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n","model.add(Dropout(0.3))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","for i in range(10):\n","    print('epochs : %d ' % (i+1) )\n","    model.fit(trainX, trainY, nb_epoch=1, batch_size=batch_size, verbose=2, shuffle=False)\n","    model.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XMJSIF9a6DpS"},"source":["trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n","print('Train Score: ', trainScore)\n","testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n","print('Test Score: ', testScore)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"lefedAnO6DpS"},"source":["look_ahead = 250\n","trainPredict = [np.vstack([trainX[-1][1:], trainY[-1]])]\n","predictions = np.zeros((look_ahead,1))\n","for i in range(look_ahead):\n","    prediction = model.predict(np.array([trainPredict[-1]]), batch_size=batch_size)\n","    predictions[i] = prediction\n","    trainPredict.append(np.vstack([trainPredict[-1][1:],prediction]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RcCdQEGC6DpS"},"source":["plt.figure(figsize=(12,5))\n","# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n","plt.plot(np.arange(look_ahead),predictions,'r-.',label=\"prediction\")\n","plt.plot(np.arange(look_ahead),dataset[train_size:(train_size+look_ahead)],label=\"test function\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"72Xre8jvNou_"},"source":["### *그 외 참고용 소스코드*"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"fMtPBW426DpS"},"source":["#### Stateful LSTMs with wider window"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"doc9k3cL6DpS"},"source":["look_back = 40\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","dataset = scaler.fit_transform(dataset)\n","\n","# split into train and test sets\n","train_size = int(len(dataset) * 0.67)\n","test_size = len(dataset) - train_size\n","train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n","\n","trainX, trainY = create_dataset(train, look_back)\n","testX, testY = create_dataset(test, look_back)\n","\n","trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n","testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2aiJimfo6DpS"},"source":["%%time\n","theano.config.compute_test_value = \"ignore\"\n","# create and fit the LSTM network\n","batch_size = 1\n","model = Sequential()\n","# model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n","# model.add(Dropout(0.3))\n","# model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n","# model.add(Dropout(0.3))\n","model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n","model.add(Dropout(0.3))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","for i in range(200):\n","    model.fit(trainX, trainY, nb_epoch=1, batch_size=batch_size, verbose=0, shuffle=False)\n","    model.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYULgw3V6DpT"},"source":["trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n","print('Train Score: ', trainScore)\n","testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n","print('Test Score: ', testScore)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"1pG-OC516DpU"},"source":["look_ahead = 250\n","trainPredict = [np.vstack([trainX[-1][1:], trainY[-1]])]\n","predictions = np.zeros((look_ahead,1))\n","for i in range(look_ahead):\n","    prediction = model.predict(np.array([trainPredict[-1]]), batch_size=batch_size)\n","    predictions[i] = prediction\n","    trainPredict.append(np.vstack([trainPredict[-1][1:],prediction]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZcmAjRhG6DpU"},"source":["plt.figure(figsize=(12,5))\n","# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n","plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n","plt.plot(np.arange(look_ahead),dataset[train_size:(train_size+look_ahead)],label=\"test function\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4EA1oxOs6DpU"},"source":["#### Stateful LSTMs, Stacked"]},{"cell_type":"code","metadata":{"id":"7qY3UhiB6DpU"},"source":["%%time\n","theano.config.compute_test_value = \"ignore\"\n","# create and fit the LSTM network\n","batch_size = 1\n","model = Sequential()\n","model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n","model.add(Dropout(0.3))\n","model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n","model.add(Dropout(0.3))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","for i in range(200):\n","    model.fit(trainX, trainY, nb_epoch=1, batch_size=batch_size, verbose=0, shuffle=False)\n","    model.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xJquKM826DpV"},"source":["trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n","print('Train Score: ', trainScore)\n","testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n","print('Test Score: ', testScore)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"hAbUcJ5P6DpV"},"source":["look_ahead = 250\n","trainPredict = [np.vstack([trainX[-1][1:], trainY[-1]])]\n","predictions = np.zeros((look_ahead,1))\n","for i in range(look_ahead):\n","    prediction = model.predict(np.array([trainPredict[-1]]), batch_size=batch_size)\n","    predictions[i] = prediction\n","    trainPredict.append(np.vstack([trainPredict[-1][1:],prediction]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hXBjrL326DpV"},"source":["plt.figure(figsize=(12,5))\n","# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n","plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n","plt.plot(np.arange(look_ahead),dataset[train_size:(train_size+look_ahead)],label=\"test function\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K4HsEN3g6DpW"},"source":["#### Stateful LSTM stacked DEEPER!"]},{"cell_type":"code","metadata":{"id":"mxim6tKg6DpW"},"source":["%%time\n","theano.config.compute_test_value = \"ignore\"\n","# create and fit the LSTM network\n","batch_size = 1\n","model = Sequential()\n","for i in range(2):\n","    model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\n","    model.add(Dropout(0.3))\n","model.add(LSTM(32, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n","model.add(Dropout(0.3))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adam')\n","for i in range(200):\n","    model.fit(trainX, trainY, nb_epoch=1, batch_size=batch_size, verbose=0, shuffle=False)\n","    model.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r35EMtaj6DpW"},"source":["trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n","print('Train Score: ', trainScore)\n","testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n","print('Test Score: ', testScore)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"ou-M4np26DpW"},"source":["look_ahead = 250\n","trainPredict = [np.vstack([trainX[-1][1:], trainY[-1]])]\n","predictions = np.zeros((look_ahead,1))\n","for i in range(look_ahead):\n","    prediction = model.predict(np.array([trainPredict[-1]]), batch_size=batch_size)\n","    predictions[i] = prediction\n","    trainPredict.append(np.vstack([trainPredict[-1][1:],prediction]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1xelE066DpW"},"source":["plt.figure(figsize=(12,5))\n","# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n","plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n","plt.plot(np.arange(look_ahead),dataset[train_size:(train_size+look_ahead)],label=\"test function\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rcpCUnhm6DpX"},"source":["#### Normal Deep Learning in Keras"]},{"cell_type":"code","metadata":{"id":"YjbZZHxX6DpX"},"source":["%%time\n","trainX = np.squeeze(trainX)\n","testX = np.squeeze(testX)\n","theano.config.compute_test_value = \"ignore\"\n","# create and fit the LSTM network\n","batch_size = 1\n","model = Sequential()\n","model.add(Dense(output_dim=32,input_dim=40,activation=\"relu\"))\n","model.add(Dropout(0.3))\n","for i in range(2):\n","    model.add(Dense(output_dim=32,activation=\"relu\"))\n","    model.add(Dropout(0.3))\n","model.add(Dense(1))\n","model.compile(loss='mean_squared_error', optimizer='adagrad')\n","model.fit(trainX, trainY, nb_epoch=100, batch_size=32, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P4FSA5s66DpX"},"source":["trainScore = model.evaluate(trainX, trainY, batch_size=batch_size, verbose=0)\n","print('Train Score: ', trainScore)\n","testScore = model.evaluate(testX[:252], testY[:252], batch_size=batch_size, verbose=0)\n","print('Test Score: ', testScore)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EF1rUMg06DpX"},"source":["look_ahead = 250\n","xval = np.hstack([trainX[-1][1:], trainY[-1]])[None,:]\n","predictions = np.zeros((look_ahead,1))\n","for i in range(look_ahead):\n","    prediction = model.predict(xval, batch_size=32)\n","    predictions[i] = prediction\n","    xval = np.hstack([xval[:,1:],prediction])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sXPlfRLZ6DpX"},"source":["plt.figure(figsize=(12,5))\n","# plt.plot(np.arange(len(trainX)),np.squeeze(trainX))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(trainPredict)[:,None][1:]))\n","# plt.plot(np.arange(200),scaler.inverse_transform(np.squeeze(testY)[:,None][:200]),'r')\n","plt.plot(np.arange(look_ahead),predictions,'r',label=\"prediction\")\n","plt.plot(np.arange(look_ahead),dataset[train_size:(train_size+look_ahead)],label=\"test function\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"S_5C1XZF6DpX"},"source":["1000개의 샘플이 있다.\n","타임스탬프는 100개이다. 즉 100 순간의 데이터가 있다. 하나의 타임스템프는 10개의 백터 길이가 있다. \n","입력자료는 1000 * 100 * 10 \n","배치사이즈는 20개이다.\n","\n","배치사이즈를 지정하지 않는다면, \n","1000개의 샘플을 모두 취한다."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"GANiwbT36DpX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nkv60Ho8CuLL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mEOOxhpsCY7G"},"source":["## **3. LSTM 모델 활용하기**\n","\n","앞서 살펴본 LSTM 레이어를 이용하여 몇가지 순환 신경망 모델을 만들어보고, 각 모델에 \"나비야\" 동요를 학습시켜보면서 자세히 살펴보겠습니다."]},{"cell_type":"markdown","metadata":{"id":"kxoDeCG5CY7H"},"source":["---\n","\n","### *시퀀스 데이터 준비*\n","\n","순환 신경망은 주로 자연어 처리에 많이 쓰이기 때문에 문장 학습 예제가 일반적이지만 본 강좌에서는 악보 학습을 해보겠습니다. 그 이유는 \n","- 음계가 문장보다 더 코드화 하기 쉽고, \n","- 시계열 자료이며, \n","- 나온 결과를 악보로 볼 수 있으며,\n","- 무엇보다 우리가 학습한 모델이 연주하는 곡을 들어볼 수 있기 때문입니다. \n","일단 쉬운 악보인 '나비야'를 준비했습니다.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_2.png)\n","\n","음표 밑에 간단한 음표코드를 표시하였습니다. 알파벳은 음계를 나타내며, 숫자는 음의 길이를 나타냅니다.\n","- c(도), d(레), e(미), f(파), g(솔), a(라), b(시)\n","- 4(4분음표), 8(8분음표)"]},{"cell_type":"markdown","metadata":{"id":"LflhttcQCY7H"},"source":["---\n","\n","### *데이터셋 생성*\n","\n","먼저 두 마디만 살펴보겠습니다. \n","\n","* g8 e8 e4\n","* f8 d8 d4 \n","\n","여기서 우리가 정의한 문제대로 4개 음표 입력으로 다음 출력 음표를 예측하려면, 아래와 같이 데이터셋을 구성합니다.\n","\n","* g8 e8 e4 f8 **d8** : 1~4번째 음표, **5번째** 음표\n","* e8 e4 f8 d8 **d4** : 2~5번째 음표, **6번째** 음표\n","\n","6개의 음표로는 위와 같이 2개의 샘플이 나옵니다. 각 샘플은 4개의 입력 데이터와 1개의 라벨값으로 구성되어 있습니다. 즉 1~4번째 열은 속성(feature)이고, 5번째 열은 클래스(class)를 나타냅니다. 이렇게 4개씩 구간을 보는 것을 윈도우 크기가 4라고 합니다. 그리고 문자와 숫자로 된 음표(코드)로는 모델 입출력으로 사용할 수 없기 때문에 각 코드를 숫자로 변환할 수 있는 사전을 하나 만들어봅니다. 첫번째 사전은 코드를 숫자로, 두번째 사전은 숫자를 코드로 만드는 코드입니다."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"TIcD7y5wCY7I"},"source":["code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n","            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n","\n","idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n","            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xjUaQ_YQCY7K"},"source":["이러한 사전을 이용해서 순차적인 음표를 우리가 지정한 윈도우 크기만큼 잘라 데이터셋을 생성하는 함수를 정의해보겠습니다."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"GyjnmpV_CY7K"},"source":["import numpy as np\n","\n","def seq2dataset(seq, window_size):\n","    dataset = []\n","    for i in range(len(seq)-window_size):\n","        subset = seq[i:(i+window_size+1)]\n","        dataset.append([code2idx[item] for item in subset])\n","    return np.array(dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yL1tII3ZCY7K"},"source":["seq라는 변수에 \"나비야\" 곡 전체 음표를 저장한 다음, seq2dataset() 함수를 하여 dataset를 생성합니다. 데이터셋은 앞서 정의한 사전에 따라 숫자로 변환되어 생성됩니다."]},{"cell_type":"code","metadata":{"id":"Ekq7WJAxCY7L"},"source":["seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n","       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n","       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n","       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']\n","\n","dataset = seq2dataset(seq, window_size = 4)\n","\n","print(dataset.shape)\n","print(dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Ev89nmsCY7S"},"source":["---\n","\n","### *학습 과정*\n","\n","\"나비야\"노래는 우리에게 너무나 익숙한 노래입니다. 만약 옆사람이 \"나비야~ 나\"까지만 불러도 나머지를 이어서 다 부를 수 있을 정도로 말이죠. 이렇게 첫 4개 음표를 입력하면 나머지를 연주할 수 있는 모델을 만드는 것이 목표입니다. 우리가 정의한 문제를 풀기 위해 먼저 모델을 학습시켜야 합니다. 학습 시키는 방식은 아래와 같습니다.\n","\n","- 파란색 박스가 입력값이고, 빨간색 박스가 우리가 원하는 출력값입니다. \n","- 1~4번째 음표를 데이터로 5번째 음표를 라벨값으로 학습을 시킵니다.\n","- 다음에는 2~5번째 음표를 데이터로 6번째 음표를 라벨값으로 학습을 시킵니다.\n","- 이후 한 음표씩 넘어가면서 노래 끝까지 학습시킵니다.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_5.png)"]},{"cell_type":"markdown","metadata":{"id":"-Pqvof71a868"},"source":["---\n","### *예측 과정*\n","\n","예측은 두 가지 방법으로 해보겠습니다. `한 스텝 예측`과 `곡 전체 예측`입니다. \n"]},{"cell_type":"markdown","metadata":{"id":"gkYjwfNma-Gz"},"source":["#### 한 스텝 예측\n","\n","한 스텝 예측이란 실제 음표 4개를 입력하여 다음 음표 1개를 예측하는 것을 반복하는 것입니다. 이 방법에서는 모델의 입력값으로는 항상 실제 음표가 들어갑니다.\n","- 모델에 t0, t1, t2, t3를 입력하면 y0 출력이 나옵니다. \n","- 모델에 t1, t2, t3, t4를 입력하면 y1 출력이 나옵니다.\n","- 모델에 t2, t3, t4, t5를 입력하면 y2 출력이 나옵니다.\n","- 이 과정을 y49 출력까지 반복합니다. \n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_6.png)"]},{"cell_type":"markdown","metadata":{"id":"vB6d_3E8CY7T"},"source":["#### 곡 전체 예측\n","\n","곡 전체 예측이란 입력된 초가 4개 음표만을 입력으로 곡 전체를 예측하는 것입니다. 초반부가 지나면, 예측값만으로 모델에 입력되어 다음 예측값이 나오는 식입니다. 그야말로 \"나비야~ 나\"까지 알려주면 나머지까지 모두 연주를 하는 것이죠. 만약 중간에 틀린 부분이 생긴다면, 이후 음정, 박자는 모두 이상하게 될 가능성이 많습니다. 예측 오류가 누적되는 것이겠죠.\n","\n","- 모델에 t0, t1, t2, t3를 입력하면 y0 출력이 나옵니다.\n","- 예측값인 y0를 t4라고 가정하고, 모델에 t1, t2, t3, t4을 입력하면 y1 출력이 나옵니다.\n","- 예측값인 y1을 t5라고 가정하고, 모델에 t2, t3, t4(예측값), t5(예측값)을 입력하면 y2 출력이 나옵니다.\n","- 이 과정을 y49 출력까지 반복합니다.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_7.png)"]},{"cell_type":"markdown","metadata":{"id":"VtPWC0yjCY7T"},"source":["---\n","\n","### *다층 퍼셉트론 모델*\n","\n","앞서 생성한 데이터셋으로 먼저 다층 퍼셉트론 모델을 학습시켜보겠습니다. Dense 레이어 3개로 구성하였고, 입력 속성이 4개이고 출력이 12개(one_hot_vec_size=12)으로 설정했습니다."]},{"cell_type":"code","metadata":{"id":"ii9tcyUTCY7U"},"source":["one_hot_vec_size = len(code2idx)\n","\n","model = Sequential()\n","model.add(Dense(128, input_dim=4, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fXkQ9fsKCY7U"},"source":["\"나비야\" 악보를 이 모델을 학습할 경우 다음 그림과 같이 수행됩니다. 4개의 음표를 입력으로 받고, 그 다음 음표가 라벨값으로 지정됩니다. 이 과정을 곡이 마칠 때까지 반복하게 됩니다."]},{"cell_type":"markdown","metadata":{"id":"63BvmS0FCY7U"},"source":["![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_train_MLP.png)"]},{"cell_type":"markdown","metadata":{"id":"qfRP2sN5CY7V"},"source":["#### 소스코드\n","\n","전체 소스는 다음과 같습니다."]},{"cell_type":"code","metadata":{"id":"m7cGftucCY7V"},"source":["# 0. 사용할 패키지 불러오기\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import np_utils\n","import numpy as np\n","\n","# 랜덤시드 고정시키기\n","np.random.seed(5)\n","\n","# 손실 이력 클래스 정의\n","class LossHistory(keras.callbacks.Callback):\n","    def init(self):\n","        self.losses = []\n","        \n","    def on_epoch_end(self, batch, logs={}):\n","        self.losses.append(logs.get('loss'))\n","\n","# 데이터셋 생성 함수        \n","def seq2dataset(seq, window_size):\n","    dataset = []\n","    for i in range(len(seq)-window_size):\n","        subset = seq[i:(i+window_size+1)]\n","        dataset.append([code2idx[item] for item in subset])\n","    return np.array(dataset)\n","\n","# 1. 데이터 준비하기\n","\n","# 코드 사전 정의\n","\n","code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n","            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n","\n","idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n","            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}\n","\n","# 시퀀스 데이터 정의\n","\n","seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n","       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n","       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n","       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']\n","\n","# 2. 데이터셋 생성하기\n","dataset = seq2dataset(seq, window_size = 4)\n","\n","print(dataset.shape)\n","print(dataset)\n","\n","# 입력(X)과 출력(Y) 변수로 분리하기\n","x_train = dataset[:,0:4]\n","y_train = dataset[:,4]\n","\n","max_idx_value = 13\n","\n","# 입력값 정규화 시키기\n","x_train = x_train / float(max_idx_value)\n","\n","# 라벨값에 대한 one-hot 인코딩 수행\n","y_train = np_utils.to_categorical(y_train)\n","\n","one_hot_vec_size = y_train.shape[1]\n","\n","print(\"one hot encoding vector size is \", one_hot_vec_size)\n","\n","# 3. 모델 구성하기\n","model = Sequential()\n","model.add(Dense(128, input_dim=4, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))\n","\n","# 4. 모델 학습과정 설정하기\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","history = LossHistory() # 손실 이력 객체 생성\n","history.init()\n","\n","# 5. 모델 학습시키기\n","model.fit(x_train, y_train, epochs=2000, batch_size=10, verbose=2, callbacks=[history])\n","    \n","# 6. 학습과정 살펴보기\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.plot(history.losses)\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train'], loc='upper left')\n","plt.show()\n","\n","# 7. 모델 평가하기\n","scores = model.evaluate(x_train, y_train)\n","print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n","\n","# 8. 모델 사용하기\n","\n","pred_count = 50 # 최대 예측 개수 정의\n","\n","# 한 스텝 예측\n","\n","seq_out = ['g8', 'e8', 'e4', 'f8']\n","pred_out = model.predict(x_train)\n","\n","for i in range(pred_count):\n","    idx = np.argmax(pred_out[i]) # one-hot 인코딩을 인덱스 값으로 변환\n","    seq_out.append(idx2code[idx]) # seq_out는 최종 악보이므로 인덱스 값을 코드로 변환하여 저장\n","    \n","print(\"one step prediction : \", seq_out)\n","\n","# 곡 전체 예측\n","\n","seq_in = ['g8', 'e8', 'e4', 'f8']\n","seq_out = seq_in\n","seq_in = [code2idx[it] / float(max_idx_value) for it in seq_in] # 코드를 인덱스값으로 변환\n","\n","for i in range(pred_count):\n","    sample_in = np.array(seq_in)\n","    sample_in = np.reshape(sample_in, (1, 4)) # batch_size, feature\n","    pred_out = model.predict(sample_in)\n","    idx = np.argmax(pred_out)\n","    seq_out.append(idx2code[idx])\n","    seq_in.append(idx / float(max_idx_value))\n","    seq_in.pop(0)\n","\n","print(\"full song prediction : \", seq_out)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C7H_l6WqCY7X"},"source":["한 스텝 예측 결과와 곡 전체 예측 결과를 악보로 그려보았습니다. 이 중 틀린 부분을 빨간색 박스로 표시해봤습니다. 총 50개 예측 중 4개가 틀려서 92%의 정확도가 나왔습니다. 중간에 틀린 부분이 생기면 곡 전체를 예측하는 데 있어서는 그리 좋은 성능이 나오지 않습니다.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_MLP_song.png)\n","\n","위 악보로 연주한 곡은 아래 링크에서 다운로드 받으실 수 있습니다.\n","\n","* [http://tykimos.github.io/warehouse/2017-4-9-MLP_one_step_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-MLP_one_step_prediction.mp3)\n","* [http://tykimos.github.io/warehouse/2017-4-9-MLP_full_song_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-MLP_full_song_prediction.mp3)"]},{"cell_type":"markdown","metadata":{"id":"X1BCtlleCY7Y"},"source":["---\n","\n","### *기본 LSTM 모델*\n","\n","이번에는 간단한 기본 LSTM 모델로 먼저 테스트를 해보겠습니다. 모델 구성은 다음과 같이 하였습니다.\n","- 128 메모리 셀을 가진 LSTM 레이어 1개와 Dense 레이어로 구성\n","- 입력은 샘플이 50개, 타임스텝이 4개, 속성이 1개로 구성\n","- 상태유지(stateful) 모드 비활성화\n","\n","케라스에서는 아래와 같이 LSTM을 구성할 수 있습니다."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"UcWxY1whCY7Z"},"source":["model = Sequential()\n","model.add(LSTM(128, input_shape = (4, 1)))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4pVDR15RCY7Z"},"source":["LSTM을 제대로 활용하기 위해서는 `상태유지 모드`, `배치사이즈`, `타임스텝`, `속성`에 대한 개념에 이해가 필요합니다. 본 절에서는 `타임스텝`에 대해서 먼저 알아보겠습니다. `타임스텝`이란 하나의 샘플에 포함된 시퀀스 개수입니다. 이는 앞서 살펴본 \"input_length\"와 동일합니다. 현재 문제에서는 매 샘플마다 4개의 값을 입력하므로 타임스텝이 4개로 지정할 수 있습니다. 즉 윈도우 크기와 동일하게 타임스텝으로 설정하면 됩니다. `속성`에 대해서는 나중에 알아보겠지만, 입력되는 음표 1개당 하나의 인덱스 값을 입력하므로 속성이 1개입니다. 나중에 이 `속성`의 개수를 다르게 해서 테스트 해보겠습니다. 인자로 \"input_shape = (4, 1)'과 \"input_dim = 1, input_length = 4\"는 동일합니다. 설정한 LSTM 모델에 따라 입력할 데이터셋도 샘플 수, 타임스텝 수, 속성 수 형식으로 맞추어야 합니다. 따라서 앞서 구성한 x_train를 아래와 같이 형식을 변환합니다."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"VAz-8PiUCY7a"},"source":["x_train = np.reshape(x_train, (50, 4, 1)) # 샘플 수, 타임스텝 수, 속성 수"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B11VhWLBCY7a"},"source":["이 모델로 악보를 학습할 경우, 다층 퍼셉트론 모델과 동일하게 4개의 음표를 입력으로 받고, 그 다음 음표가 라벨값으로 지정됩니다. 이 과정을 곡이 마칠 때까지 반복하게 됩니다. 다층 퍼셉트론 모델과 차이점이 있다면, 다층 퍼셉트론 모델에서는 4개의 음표가 4개의 속성으로 입력되고, LSTM에서는 4개의 음표가 4개의 시퀀스 입력으로 들어갑니다. 여기서 속성은 1개입니다."]},{"cell_type":"markdown","metadata":{"id":"BtZV5CQVCY7b"},"source":["![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_train_LSTM.png)"]},{"cell_type":"markdown","metadata":{"id":"p1LT7ckDCY7b"},"source":["#### 소스코드\n","\n","전체 소스는 다음과 같습니다."]},{"cell_type":"code","metadata":{"id":"s-cCGrsECY7c"},"source":["# 0. 사용할 패키지 불러오기\n","import keras\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.utils import np_utils\n","\n","# 랜덤시드 고정시키기\n","np.random.seed(5)\n","\n","# 손실 이력 클래스 정의\n","class LossHistory(keras.callbacks.Callback):\n","    def init(self):\n","        self.losses = []\n","        \n","    def on_epoch_end(self, batch, logs={}):\n","        self.losses.append(logs.get('loss'))\n","\n","# 데이터셋 생성 함수\n","def seq2dataset(seq, window_size):\n","    dataset = []\n","    for i in range(len(seq)-window_size):\n","        subset = seq[i:(i+window_size+1)]\n","        dataset.append([code2idx[item] for item in subset])\n","    return np.array(dataset)\n","\n","# 1. 데이터 준비하기\n","        \n","# 코드 사전 정의\n","\n","code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n","            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n","\n","idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n","            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}\n","\n","# 시퀀스 데이터 정의\n","\n","seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n","       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n","       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n","       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']\n","\n","# 2. 데이터셋 생성하기\n","\n","dataset = seq2dataset(seq, window_size = 4)\n","\n","print(dataset.shape)\n","\n","# 입력(X)과 출력(Y) 변수로 분리하기\n","x_train = dataset[:,0:4]\n","y_train = dataset[:,4]\n","\n","max_idx_value = 13\n","\n","# 입력값 정규화 시키기\n","x_train = x_train / float(max_idx_value)\n","\n","# 입력을 (샘플 수, 타입스텝, 특성 수)로 형태 변환\n","x_train = np.reshape(x_train, (50, 4, 1))\n","\n","# 라벨값에 대한 one-hot 인코딩 수행\n","y_train = np_utils.to_categorical(y_train)\n","\n","one_hot_vec_size = y_train.shape[1]\n","\n","print(\"one hot encoding vector size is \", one_hot_vec_size)\n","\n","# 3. 모델 구성하기\n","model = Sequential()\n","model.add(LSTM(128, input_shape = (4, 1)))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))\n","\n","# 4. 모델 학습과정 설정하기\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","history = LossHistory() # 손실 이력 객체 생성\n","history.init()\n","\n","# 5. 모델 학습시키기\n","model.fit(x_train, y_train, epochs=2000, batch_size=14, verbose=2, callbacks=[history])\n","\n","# 6. 학습과정 살펴보기\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.plot(history.losses)\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train'], loc='upper left')\n","plt.show()\n","\n","# 7. 모델 평가하기\n","scores = model.evaluate(x_train, y_train)\n","print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n","\n","# 8. 모델 사용하기\n","\n","pred_count = 50 # 최대 예측 개수 정의\n","\n","# 한 스텝 예측\n","\n","seq_out = ['g8', 'e8', 'e4', 'f8']\n","pred_out = model.predict(x_train)\n","\n","for i in range(pred_count):\n","    idx = np.argmax(pred_out[i]) # one-hot 인코딩을 인덱스 값으로 변환\n","    seq_out.append(idx2code[idx]) # seq_out는 최종 악보이므로 인덱스 값을 코드로 변환하여 저장\n","    \n","print(\"one step prediction : \", seq_out)\n","\n","# 곡 전체 예측\n","\n","seq_in = ['g8', 'e8', 'e4', 'f8']\n","seq_out = seq_in\n","seq_in = [code2idx[it] / float(max_idx_value) for it in seq_in] # 코드를 인덱스값으로 변환\n","\n","for i in range(pred_count):\n","    sample_in = np.array(seq_in)\n","    sample_in = np.reshape(sample_in, (1, 4, 1)) # 샘플 수, 타입스텝 수, 속성 수\n","    pred_out = model.predict(sample_in)\n","    idx = np.argmax(pred_out)\n","    seq_out.append(idx2code[idx])\n","    seq_in.append(idx / float(max_idx_value))\n","    seq_in.pop(0)\n","\n","print(\"full song prediction : \", seq_out)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a8ZGpgd4CY7j"},"source":["한 스텝 예측 결과와 곡 전체 예측 결과를 악보로 그려보았습니다. 이 중 틀린 부분을 빨간색 박스로 표시해봤습니다. 총 50개 예측 중 4개가 틀려서 92%의 정확도가 나왔습니다. 중간에 틀릭 부분이 생기면 곡 전체를 예측하는 데 있어서는 그리 좋은 성능이 나오지 않습니다.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_LSTM_song.png)\n","\n","위 악보로 연주한 곡은 아래 링크에서 다운로드 받으실 수 있습니다.\n","\n","* [http://tykimos.github.io/warehouse/2017-4-9-Stateless_LSTM_one_step_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateless_LSTM_one_step_prediction.mp3)\n","* [http://tykimos.github.io/warehouse/2017-4-9-Stateless_LSTM_full_song_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateless_LSTM_full_song_prediction.mp3)"]},{"cell_type":"markdown","metadata":{"id":"E99p3YwqCY7j"},"source":["---\n","\n","### *상태유지 LSTM 모델*\n","\n","이번에는 상태유지(Stateful) LSTM 모델에 대해서 알아보겠습니다. 여기서 `상태유지`라는 것은 현재 학습된 상태가 다음 학습 시 초기 상태로 전달된다는 것을 의미합니다. \n","\n","    상태유지 모드에서는 현재 샘플의 학습 상태가 다음 샘플의 초기 상태로 전달된다.\n","    \n","긴 시퀀드 데이터를 처리할 때, LSTM 모델은 상태유지 모드에서 그 진가를 발휘합니다. 긴 시퀀스 데이터를 샘플 단위로 잘라서 학습하더라도 LSTM 내부적으로 기억할 것은 기억하고 버릴 것은 버려서 기억해야할 중요한 정보만 이어갈 수 있도록 상태가 유지되기 때문입니다. 상태유지 LSTM 모델을 생성하기 위해서는 LSTM 레이어 생성 시, stateful=True로 설정하면 됩니다. 또한 상태유지 모드에서는 입력형태를 batch_input_shape = (배치사이즈, 타임스텝, 속성)으로 설정해야 합니다. 상태유지 모드에서 배치사이즈 개념은 조금 어려우므로 다음 장에서 다루기로 하겠습니다. "]},{"cell_type":"code","metadata":{"collapsed":true,"id":"LU3Sa098CY7k"},"source":["model = Sequential()\n","model.add(LSTM(128, batch_input_shape = (1, 4, 1), stateful=True))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MGMRGhiPCY7k"},"source":["상태유지 모드에서는 모델 학습 시에 `상태 초기화`에 대한 고민이 필요합니다. 현재 샘플 학습 상태가 다음 샘플 학습의 초기상태로 전달되는 식인데, 현재 샘플과 다음 샘플 간의 순차적인 관계가 없을 경우에는 상태가 유지되지 않고 초기화가 되어야 합니다. 다음 상황이 이러한 경우에 해당됩니다.\n","\n","- 마지막 샘플 학습이 마치고, 새로운 에포크 수행 시에는 새로운 샘플 학습을 해야하므로 상태 초기화 필요\n","- 한 에포크 안에 여러 시퀀스 데이터 세트가 있을 경우, 새로운 시퀀스 데이터 세트를 학습 전에 상태 초기화 필요\n","\n","현재 코드에서는 한 곡을 가지고 계속 학습을 시키고 있으므로 새로운 에포크 시작 시에만 상태 초기화를 수행하면 됩니다."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"xIIS-eBxCY7k"},"source":["num_epochs = 2000\n","\n","for epoch_idx in range(num_epochs):\n","    print ('epochs : ' + str(epoch_idx) )\n","    model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2, shuffle=False) # 50 is X.shape[0]\n","    model.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E4eACKLGCY7k"},"source":["아래 그림은 이 모델로 악보를 학습할 경우를 나타낸 것입니다. 거의 기본 LSTM 모델과 동일하지만 학습된 상태가 다음 샘플 학습 시에 초기 상태로 입력되는 것을 보실 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"5hdOKBX6CY7k"},"source":["![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_train_stateful_LSTM.png)"]},{"cell_type":"markdown","metadata":{"id":"rk_EQS1vCY7l"},"source":["#### 소스코드\n","\n","전체 소스는 다음과 같습니다."]},{"cell_type":"code","metadata":{"id":"S9dXUXO1CY7l"},"source":["# 0. 사용할 패키지 불러오기\n","import keras\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM\n","from keras.utils import np_utils\n","\n","# 랜덤시드 고정시키기\n","np.random.seed(5)\n","\n","# 손실 이력 클래스 정의\n","class LossHistory(keras.callbacks.Callback):\n","    def init(self):\n","        self.losses = []\n","        \n","    def on_epoch_end(self, batch, logs={}):\n","        self.losses.append(logs.get('loss'))\n","\n","# 데이터셋 생성 함수\n","def seq2dataset(seq, window_size):\n","    dataset = []\n","    for i in range(len(seq)-window_size):\n","        subset = seq[i:(i+window_size+1)]\n","        dataset.append([code2idx[item] for item in subset])\n","    return np.array(dataset)        \n","\n","# 1. 데이터 준비하기\n","\n","# 코드 사전 정의\n","\n","code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n","            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n","\n","idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n","            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}\n","\n","# 시퀀스 데이터 정의\n","\n","seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n","       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n","       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n","       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']\n","\n","# 2. 데이터셋 생성하기\n","\n","dataset = seq2dataset(seq, window_size = 4)\n","\n","print(dataset.shape)\n","\n","# 입력(X)과 출력(Y) 변수로 분리하기\n","x_train = dataset[:,0:4]\n","y_train = dataset[:,4]\n","\n","max_idx_value = 13\n","\n","# 입력값 정규화 시키기\n","x_train = x_train / float(max_idx_value)\n","\n","# 입력을 (샘플 수, 타임스텝, 특성 수)로 형태 변환\n","x_train = np.reshape(x_train, (50, 4, 1))\n","\n","# 라벨값에 대한 one-hot 인코딩 수행\n","y_train = np_utils.to_categorical(y_train)\n","\n","one_hot_vec_size = y_train.shape[1]\n","\n","print(\"one hot encoding vector size is \", one_hot_vec_size)\n","\n","# 3. 모델 구성하기\n","model = Sequential()\n","model.add(LSTM(128, batch_input_shape = (1, 4, 1), stateful=True))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))\n","    \n","# 4. 모델 학습과정 설정하기\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# 5. 모델 학습시키기\n","num_epochs = 2000\n","\n","history = LossHistory() # 손실 이력 객체 생성\n","\n","history.init()\n","\n","for epoch_idx in range(num_epochs):\n","    print ('epochs : ' + str(epoch_idx) )\n","    model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2, shuffle=False, callbacks=[history]) # 50 is X.shape[0]\n","    model.reset_states()\n","    \n","# 6. 학습과정 살펴보기\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.plot(history.losses)\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train'], loc='upper left')\n","plt.show()\n","\n","# 7. 모델 평가하기\n","scores = model.evaluate(x_train, y_train, batch_size=1)\n","print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n","model.reset_states()\n","\n","# 8. 모델 사용하기\n","\n","pred_count = 50 # 최대 예측 개수 정의\n","\n","# 한 스텝 예측\n","\n","seq_out = ['g8', 'e8', 'e4', 'f8']\n","pred_out = model.predict(x_train, batch_size=1)\n","\n","for i in range(pred_count):\n","    idx = np.argmax(pred_out[i]) # one-hot 인코딩을 인덱스 값으로 변환\n","    seq_out.append(idx2code[idx]) # seq_out는 최종 악보이므로 인덱스 값을 코드로 변환하여 저장\n","\n","model.reset_states()\n","    \n","print(\"one step prediction : \", seq_out)\n","\n","# 곡 전체 예측\n","\n","seq_in = ['g8', 'e8', 'e4', 'f8']\n","seq_out = seq_in\n","seq_in = [code2idx[it] / float(max_idx_value) for it in seq_in] # 코드를 인덱스값으로 변환\n","\n","for i in range(pred_count):\n","    sample_in = np.array(seq_in)\n","    sample_in = np.reshape(sample_in, (1, 4, 1)) # 샘플 수, 타입스텝 수, 속성 수\n","    pred_out = model.predict(sample_in)\n","    idx = np.argmax(pred_out)\n","    seq_out.append(idx2code[idx])\n","    seq_in.append(idx / float(max_idx_value))\n","    seq_in.pop(0)\n","\n","model.reset_states()\n","    \n","print(\"full song prediction : \", seq_out)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hiy1P4VdCY7m"},"source":["한 스텝 예측 결과와 곡 전체 예측 결과를 악보로 그려보았습니다. Stateful LSTM은 음표를 모두 맞추어서, 전체 곡 예측도 정확하게 했습니다.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_Stateful_LSTM_song.png)\n","\n","위 악보로 연주한 곡은 아래 링크에서 다운로드 받으실 수 있습니다.\n","\n","* [http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f1_one_step_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f1_one_step_prediction.mp3)\n","* [http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f1_full_song_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f1_full_song_prediction.mp3)"]},{"cell_type":"markdown","metadata":{"id":"2xvIG0TrCY7m"},"source":["### *입력 속성이 여러 개인 모델 구성*\n","\n","입력 속성이 여러 개인 경우에 대해서 알아보겠습니다. 예를 들어 '기온'라는 것을 예측하기 위해서 입력으로 '기온'뿐만아니라 '습도', '기압', '풍향', '풍속' 등 다양한 속성이 있을 수 있습니다. 상태유지 LSTM 모델에서 입력형태를 batch_input_shape = (배치사이즈, 타임스텝, 속성)으로 설정하는데, 마지막 인자를 통해 속성의 개수를 지정할 수 있습니다. '나비야' 예제에서는 현재 입력값이 'c4, e4, g8'등으로 되어 있는 데, 이를 음정과 음길이로 나누어서 2개의 속성으로 입력해보겠습니다. 즉 'c4'는 '(c, 4)'로 나누어서 입력하게 되는 것입니다. 이를 위해 데이터셋 만드는 함수를 아래와 같이 수정하였습니다."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"jG3POYl9CY7m"},"source":["def code2features(code):\n","    features = []\n","    features.append(code2scale[code[0]]/float(max_scale_value))\n","    features.append(code2length[code[1]])\n","    return features"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UJeI8YJGCY7m"},"source":["LSTM 모델 생성 시 batch_input_shape 인자의 마지막 값이 '1'에서 '2'로 수정되었습니다."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Fjg9H4dbCY7n"},"source":["model = Sequential()\n","model.add(LSTM(128, batch_input_shape = (1, 4, 2), stateful=True))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n3A0Jst0CY7n"},"source":["아래 그림을 보시면 입력이 두 개로 나누어짐을 보실 수 있습니다. 이 방식은 'c8'이니 'd4'처럼 코드 자체를 학습하는 것이 아니라 음정과 음길이를 나누어서 학습하는 효과를 볼 수 있습니다. 사람이 악보를 읽을 때도 이 둘은 나누어서 인지를 하니 좀 더 사람에 가까운 학습이라고 보실 수 있습니다.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_train_stateful_LSTM_features.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TGa-foECdLYA"},"source":["#### 소스코드\n","\n","전체 소스는 다음과 같습니다."]},{"cell_type":"code","metadata":{"id":"IoX5sMJcCY7n"},"source":["# 0. 사용할 패키지 불러오기\n","import keras\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM\n","from keras.utils import np_utils\n","\n","# 랜덤시드 고정시키기\n","np.random.seed(5)\n","\n","# 손실 이력 클래스 정의\n","class LossHistory(keras.callbacks.Callback):\n","    def init(self):\n","        self.losses = []\n","        \n","    def on_epoch_end(self, batch, logs={}):\n","        self.losses.append(logs.get('loss'))\n","\n","# 데이터셋 생성 함수\n","def seq2dataset(seq, window_size):\n","    dataset_X = []\n","    dataset_Y = []\n","    \n","    for i in range(len(seq)-window_size):\n","        \n","        subset = seq[i:(i+window_size+1)]\n","        \n","        for si in range(len(subset)-1):\n","            features = code2features(subset[si])            \n","            dataset_X.append(features)\n","\n","        dataset_Y.append([code2idx[subset[window_size]]])\n","        \n","    return np.array(dataset_X), np.array(dataset_Y)\n","\n","# 속성 변환 함수\n","def code2features(code):\n","    features = []\n","    features.append(code2scale[code[0]]/float(max_scale_value))\n","    features.append(code2length[code[1]])\n","    return features\n","\n","# 1. 데이터 준비하기\n","\n","# 코드 사전 정의\n","\n","code2scale = {'c':0, 'd':1, 'e':2, 'f':3, 'g':4, 'a':5, 'b':6}\n","code2length = {'4':0, '8':1}\n","\n","code2idx = {'c4':0, 'd4':1, 'e4':2, 'f4':3, 'g4':4, 'a4':5, 'b4':6,\n","            'c8':7, 'd8':8, 'e8':9, 'f8':10, 'g8':11, 'a8':12, 'b8':13}\n","\n","idx2code = {0:'c4', 1:'d4', 2:'e4', 3:'f4', 4:'g4', 5:'a4', 6:'b4',\n","            7:'c8', 8:'d8', 9:'e8', 10:'f8', 11:'g8', 12:'a8', 13:'b8'}\n","\n","max_scale_value = 6.0\n","    \n","# 시퀀스 데이터 정의\n","seq = ['g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'd8', 'e8', 'f8', 'g8', 'g8', 'g4',\n","       'g8', 'e8', 'e8', 'e8', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4',\n","       'd8', 'd8', 'd8', 'd8', 'd8', 'e8', 'f4', 'e8', 'e8', 'e8', 'e8', 'e8', 'f8', 'g4',\n","       'g8', 'e8', 'e4', 'f8', 'd8', 'd4', 'c8', 'e8', 'g8', 'g8', 'e8', 'e8', 'e4']\n","\n","# 2. 데이터셋 생성하기\n","\n","x_train, y_train = seq2dataset(seq, window_size = 4)\n","\n","# 입력을 (샘플 수, 타임스텝, 특성 수)로 형태 변환\n","x_train = np.reshape(x_train, (50, 4, 2))\n","\n","# 라벨값에 대한 one-hot 인코딩 수행\n","y_train = np_utils.to_categorical(y_train)\n","\n","one_hot_vec_size = y_train.shape[1]\n","\n","print(\"one hot encoding vector size is \", one_hot_vec_size)\n","\n","# 3. 모델 구성하기\n","model = Sequential()\n","model.add(LSTM(128, batch_input_shape = (1, 4, 2), stateful=True))\n","model.add(Dense(one_hot_vec_size, activation='softmax'))\n","    \n","# 4. 모델 학습과정 설정하기\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# 5. 모델 학습시키기\n","num_epochs = 2000\n","\n","history = LossHistory() # 손실 이력 객체 생성\n","history.init()\n","\n","for epoch_idx in range(num_epochs):\n","    print ('epochs : ' + str(epoch_idx) )\n","    model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2, shuffle=False, callbacks=[history]) # 50 is X.shape[0]\n","    model.reset_states()\n","    \n","# 6. 학습과정 살펴보기\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","plt.plot(history.losses)\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train'], loc='upper left')\n","plt.show()\n","\n","# 7. 모델 평가하기\n","scores = model.evaluate(x_train, y_train, batch_size=1)\n","print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n","model.reset_states()\n","\n","# 8. 모델 사용하기\n","\n","pred_count = 50 # 최대 예측 개수 정의\n","\n","# 한 스텝 예측\n","\n","seq_out = ['g8', 'e8', 'e4', 'f8']\n","pred_out = model.predict(x_train, batch_size=1)\n","\n","for i in range(pred_count):\n","    idx = np.argmax(pred_out[i]) # one-hot 인코딩을 인덱스 값으로 변환\n","    seq_out.append(idx2code[idx]) # seq_out는 최종 악보이므로 인덱스 값을 코드로 변환하여 저장\n","    \n","print(\"one step prediction : \", seq_out)\n","\n","model.reset_states()\n","\n","# 곡 전체 예측\n","\n","seq_in = ['g8', 'e8', 'e4', 'f8']\n","seq_out = seq_in\n","\n","seq_in_featrues = []\n","\n","for si in seq_in:\n","    features = code2features(si)\n","    seq_in_featrues.append(features)\n","\n","for i in range(pred_count):\n","    sample_in = np.array(seq_in_featrues)\n","    sample_in = np.reshape(sample_in, (1, 4, 2)) # 샘플 수, 타입스텝 수, 속성 수\n","    pred_out = model.predict(sample_in)\n","    idx = np.argmax(pred_out)\n","    seq_out.append(idx2code[idx])\n","    \n","    features = code2features(idx2code[idx])\n","    seq_in_featrues.append(features)\n","    seq_in_featrues.pop(0)\n","\n","model.reset_states()\n","    \n","print(\"full song prediction : \", seq_out)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j-HqOvKNCY7o"},"source":["수행결과는 곡 전체를 정확하게 예측을 했습니다.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_Stateful_LSTM_features_song.png)\n","\n","위 악보로 연주한 곡은 아래 링크에서 다운로드 받으실 수 있습니다.\n","\n","* [http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f2_one_step_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f2_one_step_prediction.mp3)\n","* [http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f2_full_song_prediction.mp3](http://tykimos.github.io/warehouse/2017-4-9-Stateful_LSTM_f2_full_song_prediction.mp3)"]},{"cell_type":"markdown","metadata":{"id":"wtEzRcZNCY7o"},"source":["---\n","\n","### 요약\n","\n","익숙한 노래인 \"나비야\"를 가지고 순한 신경망 모델에 학습시켜봤습니다. 순항 신경망 모델 중 가장 많이 사용되는 LSTM 모델에 대해서 알아보고, 주요 인자들이 어떤 특성을 가지고 있는 지도 살펴보았습니다. 앞서 살펴본 4가지 모델에 대해서 학습 손실값을 그래프로 표시해봤습니다. 다층퍼셉트론 모델 > 기본 LSTM 모델 > 상태유지 LSTM 모델 (1개 속성) > 상태유지 LSTM 모델 (2개 속성) 순으로 더 빨리 학습되는 것을 확인할 수 있습니다.\n","\n","![img](http://tykimos.github.io/warehouse/2017-4-9-RNN_Layer_Talk_loss_history.png)"]},{"cell_type":"code","metadata":{"id":"ssWFM2i0CuH4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E-Slhf2tq6ar"},"source":["## **Lab 2**"]},{"cell_type":"markdown","metadata":{"id":"ItLEd6uBq993"},"source":["다른 노래를 이용해서, 3장에서와 같은 방식으로 <u>악보를 예측하는 모델</u>을 학습하고, 출력 결과로부터 성능을 확인합니다.\n","\n","*   순환 신경망 모델의 레이어 또는 파라미터를 자유롭게 조절\n","*   또는, 사전 데이터를 참조하는 윈도우 범위<small>(e.g., 예제에서 20개 보고 예측)</small> 등을 자유롭게 조절\n","\n","실습코드의 결과를 초과하여 성능이 향상되는 구성을 만들어보고, 출력 결과를 확인합니다.\n","\n","**※ 제출방법:** 실습내용 및 출력 결과가 저장된 Colab 파일(`*.ipynb`)를 KLMS의 과제 항목에 업로드"]},{"cell_type":"markdown","metadata":{"id":"vhCTUS0trvK0"},"source":["### **<small>(참고)</small> 악보 시각화 툴 설치**\n","\n","*   Abjad 공식 홈페이지: https://abjad.github.io/\n","  - Documantation:  http://abjad.mbrsi.org/index.html\n","*   LilyPond 공식 홈페이지: http://lilypond.org/development.html\n"]},{"cell_type":"markdown","metadata":{"id":"Ziwx8ztxsMav"},"source":["#### *Abjad 파이썬 모듈 설치*\n"]},{"cell_type":"code","metadata":{"id":"6tMj66Ubedap"},"source":["!pip install abjad[development,ipython]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r6FCOWV4sO3u"},"source":["#### *LilyPond 리눅스 라이브러리 설치*\n"]},{"cell_type":"code","metadata":{"id":"A5Io9ckZfkAE"},"source":["# 설치 스크립트 다운로드\n","!wget https://lilypond.org/download/binaries/linux-64/lilypond-2.22.0-1.linux-64.sh"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"30x1o0AffxJ1"},"source":["# 스크립트 실행 후, 출력 콘솔에서 Enter 입력하여 설치 진행\n","!sh lilypond-2.22.0-1.linux-64.sh"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CEvgUenniCft"},"source":["# 정상 설치여부 확인\n","!lilypond --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JIob8LGJjAj5"},"source":["# 위 버전 확인 단계에서, \n","#   특정 라이브러리가 없다고 하는 경우, 문제해결을 위해 심볼릭 링크 재생성\n","!rm /usr/local/lilypond/usr/lib/libstdc++.so.6 \n","!ln -s /usr/lib/x86_64-linux-gnu/libstdc++.so.6 /usr/local/lilypond/usr/lib/libstdc++.so.6 "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ui4WCr7Ysx81"},"source":["#### *악보출력 기능 확인*\n"]},{"cell_type":"code","metadata":{"id":"ih3KzZVypmIs"},"source":["%load_ext abjadext.ipython"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gwpwK4C3eZGu"},"source":["import abjad\n","seq = \"c'16 f' g' a' d' g' a' b' e' a' b' c'' f' b' c'' d''16\"\n","voice_1 = abjad.Voice(seq, name=\"Voice_1\")\n","staff_1 = abjad.Staff([voice_1], name=\"Staff_1\")\n","abjad.show(staff_1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cDt09hNjtEEp"},"source":["### **신규 악보 및 코드 작성영역**\n"]},{"cell_type":"markdown","metadata":{"id":"dSLHaQsiwrGp"},"source":["#### *신규 악보: 비행기 (동요)*"]},{"cell_type":"code","metadata":{"id":"uzbRwfthte3k"},"source":["seq_lab2 = \"e'8. d'16 c'8 d'8 e'8 e'8 e'4\"\\\n","            + \" d'8 d'8 d' e'8 e'8 e'\"\\\n","            + \" e'8. d'16 c'8 d'8 e'8 e'8 e'\"\\\n","            + \" d'8 d'8 e'8. d'16 c'1\"\n","\n","voice_1 = abjad.Voice(seq_lab2, name=\"Voice_1\")\n","staff_1 = abjad.Staff([voice_1], name=\"Staff_1\")\n","abjad.show(staff_1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"47Hdg5Caw2AT"},"source":["#### *코드 작성영역*\n"]},{"cell_type":"code","metadata":{"id":"jVYEYS15wpi6"},"source":["######\n","## 3장 내용을 참조해서 Lab2를 작성하세요.\n","######\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]}]}